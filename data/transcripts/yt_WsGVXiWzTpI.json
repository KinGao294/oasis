{
  "source": "youtube_caption",
  "language": "en",
  "full_text": "Hi everyone, welcome back to another build hour. I'm Michaela on the startup marketing team and I'm here today with two members of our solution architecture team. Emry live in the studio and Brian joining virtually to help address Q&A throughout the hour. >> Hi, I'm Emry. I work as a solution architect at OpenAI supporting digital native customers on building various of AI use cases including longunning AI agents. So today's topic is agent memory patterns which is a very exciting topic in Emry and I's first ever build hour. So if you've been following along, we started with how to build agents from scratch using responses API, then moved into agent RFT and today exploring agent memory patterns. All of the sessions are up on our YouTube channel, so definitely check them out if you want to catch up or revisit earlier builds. Though the focus on the build hour is to empower you with the best practices, tools and AI expertise to scale your company using open AI APIs and models. So for today's build hour, we'll start with an introduction to context engineering, the foundation for agent memory, and then Emry will walk through several live demos covering memory patterns like reshape and fit, isolate and route, and extract and retrieve. We'll end with best practices, resources, and of course, live Q&A. On the right hand side of the screen, you can drop questions into the Q&A box any time during the session. Our team is monitoring both in the room and virtually to help answer throughout, and we'll save a few for the end to go through live. All right, with that, I'll hand it over to Emry to kick things off. >> Thanks, Michaela. Hi, everyone. Um so I'll start the first part of this um the session with context engineering definition. So this nice definitions from Andre Karpati. I'll start by emphasizing that the context engineering is both an art and a science. So it's art because it involves judgment. So you have to decide what matters most at a given step of uh a reasoning or action processes. It's science because there are concrete patterns, methods, and measurable impacts to make context management more systematic and and repeatable. So, I'll highlight that modern LLMs don't just perform based on the model quality, but they perform based on the context you you give them. In this slide, I want to talk about different disciplines that comes together to basically present the context engineering. Uh so it is a broader discipline than any single technique like prompt engineering or or retrieval. So the diagram visually represents the ecosystem of context optimization layers that together shape uh what the model sees and and understands. So you see prompt engineering uh as as a core principle structured output rack state and history management memory is also a crucial part. So using persistent or semi-persistent storage like files, databases or memory tools to upload and retrieve key information and all of this is contained inside the larger sphere of context engineering. Um so we can also connect these capabilities into different uh product capabilities. Here is a nice summarization slide um that talks about the the core principles um like why it matters because longunning tools longunning and tool heavy agents blood tokens and degrade quality uh via uh poisoning noise and and and confusion and and bursting. We have three core strategies uh as we discussed in the beginning like reshape and fit uh to the context window, isolate and route the right amount of context to the right agent and extract high quality memories to retrieve uh in the right time. We also have prompt and tool hygiene as a core principle. So keeping system prompts lean, clear and well structured. uh use a small canonical set of uh fusion examples and minimize overlap in tools and get the tool selection. And our goal in Northstar is basically aiming for the smallest high signal context that maximize the the likelihood of the desired uh outcome. And then in this slide is where our transition from why context injuring matters to how to to actually do it in in practice. So I'll frame this as a toolkit of of techniques. So these are not mutually exclusive. So most real world agent architectures combine multiple strategies depending on the use case uh and the context budget. So the first technique is reshape and fit. We can apply context trimming, compaction and summarization. The second one is isolate and route. uh we can offload context uh and tools to specific sub aents with a selective handoff and the last bucket is extract uh and retrieve um we can talk about memory extraction state management and memory retrieval in in that last um bucket when we talk about context engineing it's essential to distinguish between short-term and long-term memory because they solve very different problems uh I think we group uh the first two bucket as short-term memory which we also call as insession techniques and then the last bucket is long-term memory uh we call it cross session. So that means you can um collect different information from multiple sessions uh and you can retrieve back in in the next session or other sessions uh in in the future. So short-term memory is all about like making the most of the context window uh during an active interaction and active conversation. Uh and then in contrast long-term memory is is about building continuity uh across across the the sessions. Cool. So we we often get excited about how powerful our agents are becoming how AI models are getting them better and better. They can handle complex tasks uh route between tools. They can plan multi-step workflows. But underneath all that there is a there is a core bottleneck because context is is finite. So every piece of information we add to the prompt instructions um conversation history tool outputs competes for a space in in a fixed uh token budget. And this is why uh it matters slide. Uh I want to make the problem concrete here. So I'll frame it around before and after contrast. So you see two conversations. Um what happens without memory on the left and what happens with memory on the on the right. So on the left hand side um the user started with the issues like Wi-Fi, battery and over overheating in it troubleshooting agent. After many turns the agent has forgotten the earlier context. it falls back to reasking for information that the user already gave. Right? But on the right hand side, the agent remembers the original issues even after many turns. It can pick up the unresolved thread. Uh it references previous actions like firmware update, background sync which makes it feel intelligent uh and reliable. So this is such a stateful behavior which is the foundation of uh a longunning agent. Now I'll switch gears to to failure mode. So we can group these failure modes into four categories. The first one is context burst. So you can imagine it as a sudden token spike in one of or multiple components um to do the limited external control or increased calls. Context conflict if there's any contradictory instructions or information in your context. Context poisoning uh if there's an incorrect information uh that enters the context and propagates over the turns. It can be via summaries or memory objects, state objects you're injecting into the context. And then finally context noise. So you can imagine it as multiple um tool definitions or like way more many many tool definitions uh coming into your context at the same time. This can be redundant or overly similar items. So that can make a noise uh in the context. Uh here's a nice um visualization of context burst uh in tool heavy workflows. So you'll see that um there will be like a specific increase uh in one specific turn and you'll be injecting uh like large amount of tool tokens here. And then the next one is is context conflict. So we can easily visualize it here. So you can imagine in one of the turns uh there's specific tool call and here in this tool call you see that in the system instructions I never issue a refund if warranty status is not active. But in the middle of the turn you're also uh saying that it's eligible refund for VIP customers. But at the end of the turn and and your agent is responding, hey, you know, given your urgent travel, I can issue a full refund. So, this is a nice vis visualization or example for the specific um context conflict that can be coming from uh one of the the tool results. And then last one is context poisoning. uh so you can imagine it as a hallucination or something inaccurate mixed into the context in any step and propagates across different terms. So here we have a couple possible pitfalls here. Uh losses summarization edits can can be causing this. If you're using a free form uh note that accumulates over time that can be contradict and then finally uh older summaries override the newer ones and you'll be basically uh causing any hallucinations uh because of the summary logic and you'll be injecting that hallucination into the into the context and propagating uh over time. Cool. Now I'll stop sharing my screen and switch to the demo that I prepared for you. Uh and then I'll go over all of these some of these challenges um to show you like how it actually works in a real world scenario. Okay, let me share my screen. Cool. So here I prepared a demo app for for this build hour. It is an ID troubleshooting agent for software solving issues uh for for issues related to both software and hardware. Uh and this is a dual agent demo that lets you run two agents side by side. So backend logic states inside the nextJS app and I'll be using OpenAI agents SDK. So we have two tools connected to to that agent. One of them is get orders and other one is get policy. So here I can start sending a message uh and saying hi to to both of the agents, right? Uh and then you'll see that both of the agents are are responding to my message and then here I can say hey my laptop fan is making weird noises while I playing games. Is it normal? So here you see that the the configuration for both of the agents are same. They're at the same model, same reasoning level. um but I'm sending the same message and there is no memory um basically there is no memory configuration yet. So here you also see the context usage bars at the at the top. So you're you're seeing different type of components uh that is already in the context now. Um and I can say hey before I want to see my orders my order number is 1 2 3 uh four five and so now I'm expecting the model to to make a tool call and show me uh the orders I have. So here you see that the order status the items I have and it's powered by a specific tool called. So as you see over time um it will accumulating different tokens and different type of tokens here and [clears throat] in the context life cycles I'm visualizing what is happening under the hood across multiple turns. So here you see that I have uh 84 tokens of system instructions. My user input is increasing uh slowly. Uh but the core component here uh is agent output that will be generated by by a model. Cool. Um so this is a typical real world scenario. So now I also want to showcase like how context burst is is happening. So I can still uh start with high um and I can say hey this time I'm having an overheating issue on my laptop uh and then the model is responding to to my to my message to my issue basically uh and then here it's telling me like specific um instructions and it's asking me some questions to better understand uh what's happening right and then I can say hey thanks before that I want to see the refund policy of my MacBook Pro 2014. So while I'm sending this message, I also want to quickly show you the code and core concept of or how it's working. So it's powered by open agent SDK and here you see um the agent definition. So it's a customer support assistant. Uh I'm having specific instructions here um that I'm adding. Uh I'm using like different models here. Um, and also I can show you the system prompt really quickly instructions. Um, so it's basically I'm I'm saying that hey you you're a customer support assistant for for devices. Uh, and then I'm using like very slight prompting and instructions for for that specific uh agent here. So let's go back to um the response. So, since I asked about the the specific refund policy for from a MacBook Pro 2014, uh it's made a tool call get refund and it's basically returning uh a specific um refund policy that I added before. So, here you see that in between turn two and turn three there is a specific spike um in the in the context window. So, in turn two, I I I had maybe around like 300 400 tokens, but now I have more than 3,000 tokens because I am just dumping lots of information into the context. And then this is a nice example for for context burst here. um instead of maybe just dumping all of these information into the context uh as as a refund policy, I can be more careful about my tool definitions and tool outputs um to basically make a decision about like what should I inject into the context. So maybe not all of these information are are valuable, but as you see that I'll be injecting lots of information into the context that's visualized here uh in this context life cycle tab. Cool. Now I'll stop sharing my screen and go back to to the deck. So I'll continue uh with the next uh steps here. Okay, nice. So, we talked about challenges and what's going on under the hood and a specific example about context. So, now let's talk about the solution, right? Um so the solution is basically uh managing context efficiently using different techniques such as um tming compaction uh state management memories and make the natural step beyond prompt engineer. Uh again this is also another visualization about different components in the context. Uh so you see that across the times it's increasing the token counts are increasing and these these tokens can be coming from the system message user message maybe you might be injecting uh memories or maybe you might be injecting different uh type of specific tokens that can be added into your context. Uh here I want to group uh AI agents in terms of context profiles. So we can group them into three categories. So first one is rack heavy assistance. So you can imagine reports policy QA agents. Um in these type of agents context is most dominated by retrieved knowledge and citations. The second one is tool heavy workflows. Uh context is mostly dominated by frequent tool calls and returned payloads. And last one is conversational concier. So you can think about planning agents, coaching agents. uh and in this case context is mostly dominated by uh growing dialogue history. There'll be lots of tokens in conversation history like assistant usage tokens that scales with uh with session lengths and then to better understand the the solution and uh the techniques uh we can go over what is fixed in our context and what is dynamic and and a variable. So here you see different type of components like usually system instructions tool definitions and examples unless you're doing a rack uh approach is is mostly static in the context. What is dynamic is is tool results retrieved knowledge memories and and conversation history. So these are the nice examples for dynamic u and static context and tokens. uh so you have a control on dynamic tokens and you can apply different techniques to to control it efficiently. So I would like to start with prompting best practices to aid avoid context conflict here. Um you can also find it from our our prompting guides and cookbooks. Uh the first rule is being explicit and structured. We suggest you to use clear direct language and specific enough to to guide action. uh you should give room for planning and self-reflection. I think this is becoming more and more important with uh reasoning models like GPT5. Uh and you should avoid conflicts. So keep the tool set small and non-over overlapping. Don't use uh ambiguous uh definitions. Even if a human can pick a tool, the model won't either. So be careful with conflicting instructions and and tool definitions. So for context noise, we talked about like many many tool definitions and many tools attached into the context as as an example situation. Um again, you you should be explicit and structured in your prompts. Um more tools isn't always equal to to better outcomes. Uh so favor targeted tools with clear tool decision boundaries and then return meaningful context from your tools. So in the demo um you show that specific uh example of context burst. So we suggest you to control basically what is the tool output uh and then return high signal semantically useful fields um and prefer human readable uh identifiers. Nice. So now I'll switch gears to engineering techniques and I'll start with the first one which is reshape and fit. So the first technique here is context trimming. So it is a pretty basic technique. It basically means that dropping older turns while keeping the last uh end turns. Uh here in the turn we have like limited context. Uh it's getting getting noisy. There are lots of information in the context. It can be coming from a tool user message or different sources. And there's higher likelihood of losing track because uh we are getting close to to context limit. But once we trim the older uh conversations, older messages uh now we have fresh context. It has better attention uh and you'll see that uh it will also increase the latency uh that you're using. So it basically keeps the last end messages and trips the the previous older messages. Uh and these are the some parameters and knob we have control over in in context trimming. The second technique is context compaction. uh it basically means just dropping tool calls or tool call results from the older terms while keeping the rest of the messages. So if you have a tool heavy agent, you can consider these techniques. Um you'll see that your context will be most dominated by tool results. It will be noisy. There will be maybe some context noise and lots of information coming from different tools. And after compaction you'll see that there will be fresh context uh better attention and and faster uh processing uh and you will also be keeping the tool placeholders uh intact after even after the context compaction here and a question you might have uh would be like okay how can I decide heristics about trimming and compaction uh so here I can share a couple suggestions so first you can you can analyze your sessions uh you can collect like context snapshots from from production or from your users. You can collect times down and dislike context to see what's going wrong there. Think about the average token size of a context. Uh what type of task do you have in one session? Secondly, um like do not trim mid turn and break turn blocks. So a turn basically means that a user message and all the other message until the next user message, right? Uh so if you just break or or don't respect these turns uh there will be higher likelihood of losing track. And then finally don't wait to hit context window limits. Uh so keep track of of context allocation. You can set thresholds like 40 or 80%. So if you're getting closer to hitting the context window limits, uh these thresholds will help you to to better understand basically uh when you should trigger some of these operations. You can control tool outputs uh and you can also keep track of token saves. So these techniques are also really nice for for cost um cost reducing cost purposes. Uh, and you can always keep track of like how much token you're saving while you're increasing the the overall capability of the of your agent. And then the next technique we have is context summarization. Um, so it basically means compressing prior messages into structured summaries and you can inject into the context history. So here uh in turn n you see lots of messages uh like noisy context again and you're basically keeping the last n messages and just summarizing or compressing the previous ones um so that you'll have fresh context uh better attention faster processing and at the end of the day you'll have a golden summary. So this will be like a a valuable information because you'll be basically compressing all of the valuable informations. Uh and at the end of today it will have like a very dense um object that you can keep track of and that will be also useful for you to better understand what happened in the conversation. And here's a nice visualization uh in the context life cycle uh about the summarization. So let's say you perform the summarization a specific turn. So you'll see that you are compressing uh all the previous information and injecting it back uh into as into the context as as a memory object. So you see there is a new component um called as memory after the summarization performed. Nice. Um so here here is a comparison of summarization versus trimming. Uh so there are different dimensions that you can consider while you're designing uh a memory pattern for your for your agent. Um you can see that in trimming uh you'll just keep last entrance and you'll be dropping the oldest ones. So basically it'll be pretty straightforward operation. So it'll be very fast uh you know and there's no no latency. Uh but the trade-off is that you you might be losing some information uh that is already there. So I think this is the main main trade-off that we have. Uh it's it's really best for tool heavy ops and and short uh workflows. And then in in summarizing, you're basically just keeping track of all the information. So you you're not throwing away any anything. Uh this can add this can add a little bit of um latency and cost because you'll be doing another summarization call to a model. Uh but you'll be just collecting all the information. So you can think about a uh an agent or use case. If you have like multiple tasks in your longunning agent that are independent from each other, you can definitely consider u trimming because probably the trimmed or throwed away information is not important for the agent for the next turns. But if you're collecting useful information across multiple turns and tasks are dependent to each other, then you can definitely consider uh summarization here. Nice. Uh so now I'll stop sharing my screen and go back to to the demo. I'll show you couple examples of these techniques that we already covered here. Let me quickly share my screen. Nice. So here let's go to configurations page uh on the demo. So for agent P I want to uh enable trimming and I can basically set max turns S3 to trigger uh trimming operation. I want to keep recent turns uh as S3. So here I can start again to test my my agent and saying hi. So this time I want to understand the refund policy um that I want to to check. Maybe I want to refund the laptop I just bought. I can say, \"Hey, I want this refund policy for my MacBook about a month ago. Uh, and I want to understand like what's happening here um in in terms of refund. So if I'm eligible or if I'm not eligible. So the model is now making uh a tool call uh and calling the get refund tool. Here as you see it's returning that specific information. I have 30 return window for uh for returning that specific laptop. And I also want to check my my order. So I changed my mind and I'm saying, \"Hey, can we also check my order? My order number is 1 2 3 4 5.\" Uh and I want to see like if it's if it's on the way, if it's coming. So you see that the model is doing another tool call as as get order. And now I want to switch gears. I can say, \"Hey, thanks. I'm having an issue with the internet connection. So until this turn, you see that I have lots of tool tokens here in the context in context life cycle. So it's getting uh accumulating over turns and in that specific turn now it's telling me that hey let's sort it out. It's asking me a couple questions um about my my device and I can say hey I tried to to load an internet page and still see 40 404 error. Um I basically share a couple uh important information about the situation and you see still see that the across the turns it's accumulating lots of lots of tokens and even agent output is is increasing. Okay. So let's say it's still happening on on Safari. Um and then this is the last message probably uh that I that I want to share about the current situation and I'm waiting to to have more guidance and instructions uh here. And here you see that at the end of turn six the context is trimmed. Uh if I go back to here to visualize what's happening. So when I hit the the turn six, you see that it trimmed the context. So it basically removed all these tool tool outputs and tool tokens. So now I have a fresh context here. Um and then now I can continue talking about the same specific issue or I can continue to to talk about like different different information. Nice. So let's go back and then here I also want to show you how summarization works. So also the compaction is also works in a similar way as a trimming. So here I can set uh like compaction trigger as for and keep recent recent turns too. So you'll see that at the end of turn two, it'll be compacting and removing all these tool outputs and I'll have a a fresh context similar to to the trimming approach. But now I want to be a little bit more advanced here. So here I want to enable summarization. Um I want to set the the summarization trigger as five and I want to keep the the recent three turns. So here I I clicked save and now I want to just see how it's summarizing all these information. So here I'm sending hey I I'm having internet connection again. So this time I decided to share more and more information about my my situation. So I can say where I bought this computer um what is is the model. So I can say, \"Hey, I have a 2014 MacBook Pro 14inch and I live in the US, but I bought it from Amsterdam. I received it from from battery change service and just updated the OS version last week and they asked me to update the OS version to Mac me OS Seoia. So as you see, I'm sharing like many information uh and these informations are really available for an IT trouble troubleshooting agent, right? Uh and here I can go back and say okay these are nice clarify the problem uh like what I need from you and I can say hey I already tried hard reset after checking the FAQ docs but it didn't work. So this is still in a form of memory because I'm sharing like which steps I tried which worked and and which didn't work. I can go back um and continue talking with the agent. So now it's reasoning itself and providing me like more detailed guidance uh and instructions for specific to to a MacBook. So I I go back I went back to my computer and I saw that the Wi-Fi icon is is not active. Um and then I'm thinking maybe it's related to to Wi-Fi or maybe it's related to a specific um software issue. So, as you see across the turns, it's it's getting more complex. The the the agent needs to reason and the agent also needs to keep track of what's in in its context and make sure that it's not uh there's no burst, there's no conflict. Um there's no poisoning and other type of failure modes. It's telling me uh some specific steps and I can say, \"Hey, I tried it already and I'm wondering if it's a specific software issue, right?\" Um and then here I'm waiting for the response from from the agent. So again, I shared lots of information here. Uh lots of available information. So now the agent knows my device, where I bought this device, which steps I tried. Um and basically what I what type of um steps I performed before uh doing that. Cool. Uh so now you see that it's responded to me like a very well structured instructions given what you described. Wi-Fi icon is not active blah blah. And then here I see that the context is summarized and I notice that there is an orange uh component we count as memory item and the memory item is basically um the summary uh that we had. So here between turn four and turn five you see that I'm I'm condensing some part of the context and I'm injecting it back as a user message uh as as a memory component. So again here memory is basically um the the summarized context from the previous terms. So now I want to go back to the code and show you the the summary prompt uh and go over like some important topics about this specific prompt. So as you see uh here's my summary prompt. I'm saying hey you are a senior customer support assistant for tech devices setup and software issues. Um, and then before you write, I'm saying, uh, hey, be careful with contradictions. Uh, make sure you are having a temporal ordering and make sure you're having a hallucination control. So, I think these are very important things to consider when writing a well-crafted summarization prompt. And then I'm tying this summary to my specific use case. So, I'm saying, hey, in your summary, write a structured factual summary. And then just think about product environment reported issues, what worked and what didn't work. Uh which steps you tried, include identifiers, which is important, key timelines, uh timeline milestones, tool performance insight, current status, and next recommended steps. So this is a really nice example of how to craft a summarization prompt. Um, and then here if I go back to the context summary, I'm seeing like lots of useful information. So now I'm seeing, hey, the device is is MacBook Pro. The the operation system mecha it's bought from it's purchased in Amsterdam, but location is the USA. You see like which steps I tried even uh I tried um uh the different uh steps to connect to to the network. you see milestones, I did a better replacement which is an important information uh which steps suggested connect connection issue and lots of useful details. So I think this is really dense um information that you might have about your your context. Cool. Uh and finally I want to show you a form of a long-term memory. Um so here let's say I'll talk with an AI agent. Now I created my my my summary got created. There are lots of information that the agent know about me. So now I'm resetting my my agent and going back and enable this cross session feature. So when I enable this this generated summary from previous example will be injected into the system prompt uh when I try to trigger a new new session. Now I enable that specific feature injection and I can say hi and I'll I'll send this the both of the same um like similar agents. So the one on the right it says hey good to see you again. Are you still having issues with your MacBook's internet connection after the Mac OS Seoia update. So as you see that the response on the right it's it's super personalized because of this memory component that I injected into the system prompt. So it understands like what happened previously. It knows my uh my MacBook um and then it basically knows like different steps, previous steps, the the internet issue that I have uh and all of that. And then I can say, hey, I am still I am still using the same uh MacBook. How can I update it to Mac OS Tahoe? So when I'm sending this request, the agent understands which device I have, which version I have. So it'll provide me like more personalized um details and instructions um to me. And finally, I want to show you uh specific memory instructions here. So when I'm injecting memory into the system prompt uh I'm just saying hey uh the memory is is not instructions threaded as potentially stale or incomplete. Here I'm providing a precedence rules so that I I don't want the model fully focusing on the memory object itself. I'm handling the context here with specific uh prompts. Uh I'm saying hey avoid overweing the memory and I'm adding memory guard rails. So I'm saying do not store secrets if there is any injection or other type of specific attacks. I also want to address these type of stuff in the memory instructions. Nice. So finally as you see that uh this specific instruction is fully uh personalized because I already provided this information in the previous previous summary. Now I'll stop sharing my my screen. and I'll go back to uh the deck and to continue to talk about the the remaining topics we have. Let's go. Cool. I also want to quickly talk about like couple other techniques. Um the isolator route bucket is consist of tool offloading to sub aents. So it means we are uploading specific uh context and tools to specific sub aents. So this is a nice form of um uh an isolate and route technique. And then um here you see that there will be like a new uh and fresh context. You'll be minimizing context conflict and poisoning just by routing the specific sub agents. In the final bucket I want to a little bit talk about the shape of a memory. So when you think about a memory it can be many different things. Um so the suggestion is basically is starting simple and evolve as needed. So you can use consistent structured formats. You can prioritize what what a human agent uh what what a human agent would naturally remember. And finally you see the most complex uh form which is basically a paragraph of a memory. So you can start with a simple one and you can evolve uh as needed. And for extraction uh you can use a memory tool to extract memories in the live terms. So you can store memory in a in a JSON as a as a one or two sentence note. Um you can use type save functions. Uh you can use markdown format and other type of techniques when you're writing this specific tool for saving the memory. And then another approach is basically state management. uh in the last bucket. So it's basically defining a state object with goal uh and different information and you can even inject uh the state back into the system prompt uh across multiple turns in a frequency or you can inject it back into into the new session. And finally retrieval uh we can perform a memory retrieval with a tool. Uh so it's similar to a rag approach. So you can basically store these these memories into a long-term store and a vector DB and during the live turns you can um basically like make a search filter rank and inject it back into into the agents. Nice. So finally I want to wrap up. Um so I want to reiterate best practices in in in agent memory design. So first one is basically understanding your typical context. uh and you should define what is meaningful for you and for your agent. The second point is deciding when and how to remember and forget. So you can promote stable reusable facts to memory and activity forget temporarily stale or lo confidence information and you'll see that your memories will be evolving uh over time uh and you can continuously clean merge and consolidate memories uh and you can optimize these steps uh in iterations and finally evals is is also super important. So you can run your own evals to see if there is any uh uh improvement with memory on and off. You can even build your memory specific evals for long running task and and long context. >> Awesome. With that, let's move on to some Q&A. We've had a ton of great questions come in. So why don't we re refresh the presentation and we'll pull up the next slide and get into a few. >> Nice. Okay. So let me go back to the Q&A session and jump into the questions we have. So let me quickly share it again. Nice. Okay. Yeah. Let's start with the the first questions. Yeah. So there are li any libraries or packages uh to recommend for context engineering. So this demo is built by using uh open agents SDK package and library. It gives you a really good flexibility um to implement your own sessions. Uh and in these sessions you can easily implement like trimming, compaction, summarization and all of that type of uh techniques easily here. Um so I see many different libraries uh that are evolving really fast to basically um make your life easier for for context engineering. So as you see we have too many um techniques and each technique has different parameters to tune. So I also see that uh there is an uh evolving uh part of the all of these um libraries but I can suggest open agents SDK as a starting point uh to basically start implementing specific uh context engineering techniques uh and and go from there. Nice. Next one. So how do you evaluate or measure uh the memory feature is evolving uh the memory is improving performance. So this is a really nice question. Um yeah after this the session you might think about hey you know I implemented a specific memory approach but I don't know if it's if it's good or or not how it's performing well. So we can maybe split this into couple um uh portions. So first one is basically just running your your regular evals with memory and and without memory. So I think this is a really nice way to to start thinking about if if memory feature works or not. So if you have some specific eval metrics like completeness uh like upwards downloads or that type of uh numeric metrics you can see if there's an increase or decrease or if there's any statistically significant uh uplift coming from the memory uh and then maybe your evals might not be capturing well that type of um memory based boost or improvement then I I suggest you to think about more memory based eval. So what I mean by memory based eval is basically uh evaluating the model on long running tasks and long context. So if you are not hitting any um context thresholds maybe uh your agent uh doesn't need any of these memory um improvements at all. So again you can start with your core core evals if you have already and then secondly you can start creating your own memory based evals. So you can even evaluate the the quality of the summary, you can evaluate the injection time, you can evaluate the injection prompt. So there are different ways to to evaluate it. Uh but of course in most EVAs you also might need to prepare a golden data set first and think about maybe like couple 50 examples like golden examples of a of a good summary or you can try different horistics that I mentioned before to basically find the right balance of trimming uh and compacting. So I think we can just group this into three different buckets. First one is running your own evals to see see if there's an uplift. Second one is building memory specific evals. And the third one is basically finding the right heristics uh and parameters to apply in the in the context engineering techniques. Next one. So should we use hierarchical context like entire project context for immediate task and context for immediate file edit in questions? Um so yes the qu the answer is yes but it's mostly dependent on the use case. So we also have a a concept called memory scope. So you can think about this memory scope as as a global scope that means if you have a customer or user of your agent probably there are some information that you should always remember about that specific user. Maybe this user likes more friendly tones. Maybe this this user lives in the US. So these are some examples for global memory. Um but you can also have um uh a scope based on the specific session. So let's say I want to uh book a travel uh and then this time I prefer window seats because I want to sleep. Uh so this also a nice example about the the session scope and session memories. So I think this is a good practice to maybe separate these into two two buckets and you can keep track of uh session memories with session scope and over time you can graduate session memories into global memories and you can keep track of like what is really important uh about uh the specific user. So in travel concier example if user is always saying hey this time I want window seat uh like maybe multiple times and you can finally graduate that memory into global memories and keep track uh keep it in in agent's mind basically and remember that for the next uh next bookings. Nice. Okay. So what strategies do you do you use to keep memory flash or prune so the agent doesn't become overloaded with stale or yeah this is a really um this is another good question uh and in the real world you see that memories are are evolving really fast so after some time you'll see that there are some memories that you need to prune and the agent needs to forget. So in that specific case there are a couple techniques to apply. So first of them first of it is basically keeping a temporal tax. Okay, I I learned this memory uh from the user but I learned it maybe like two months ago. So if you can keep track of these um timestamps uh or temporal tags, the model will understand what is old and what is new. So if I say I like dogs, if I said I like dogs like two months ago and today I say I like cats. So you'll see that the model is going to understand my favorite animal now is maybe cats and it will override the memory um with the right instructions. So this also falls into a little bit to memor consolidation. So how to prune uh stale memories, how to basically update uh and override the new ones into the existing ones. So temporal text is one technique that you can apply. Uh the other one is you can use a way decay or um basically a window function uh and you can basically uh focus more on the recent memories uh and you can basically downgrade the the oldest ones. So it really depends on the nature of your use case. So if you think that what I said a year ago is not important for your agent, uh you can definitely prune these old ones and implement a weighted average probably for all your memories. But if you think that all of this memory is is equally important for your agent, then you can consider maybe like memory consolidation and memory override with temporal text. So we can talk about two different uh techniques um to manage the overloaded and stale uh memories. Nice. Okay. So how do you manage scaling agent memory systems when you have many users with individual and shared memory pools? Yeah, this also another good good example from real world. Um so once you see the memories are are uh evolving over time and you'll see that you're collecting tons of memories from um from your users. Um so there are different ways to scale it. I think the first path or first first decision criteria starts with if you are basically performing uh a retrieval or search base long long-term memory approach or you're just using um basically summarizing the the context. So if it's the the second one that means you're just storing all of this information and persisted into into a disk. So you can think about some scaling methods about like data management how to manage like a large amount of memory nodes uh as a text in a text format or you can basically think about um scaling the first approach which is basically you have to think about like how to scale a search uh and retrieval system. you might be storing all of this information um into into a vector database and then in this vector database you can try to scaling uh the storage you can scale all these all these vectors filtering ranking system and all of that so I think the first bucket is mostly about this long-term memory so we talked about like memory as a tool so if you can think about extracting memories with a tool and retrieving back during the live turns probably this is the situation where you're going to uh hit this question about scaling uh for many users. Uh in this case you can think about u scaling techniques for vector databases. Uh you can use shorting you can optimize your embeddings model probably if you're using like customized embedding model. Um and you can basically optimize retrieval process similar to to a rag approach. Uh again the first one uh is mostly about scaling a retrieval system. Uh the second one is mostly about basically like data storage, how to store specific data, how to manage uh like tons of information and sentences. I think to wrap up uh we can basically put it into two buckets. One of them is uh scaling um and optimizing a retrieval system. Uh the second one is is also u making more efficient for storing and persistent uh in in the disk. So this is also a common question that I hear from from my customers. Um I think you can maybe follow like a like pilot approach and you can turn on this new uh memory techniques for for for a subgroup of your users and you can think about okay how it's evolving over time. Maybe you'll see that most of the memories that your users are saying are pretty limited. So think about this travel concier agent. So probably I'll just sharing my my memories about my seat preference. Maybe if you want to book a hotel, I like maybe higher floors. Maybe I like the specific menu or breakfast. Uh so I think this is more limited type of groups uh type of memory memory possibilities I can say and that type of agent. But you are if you're building a life coach or life coach agent. So there are tons of memories that you need to remember uh about me my life. uh and you'll see that these type of memories and memory pools are evolving really fast. So yeah the third point is that try to understand the the evolution of memory and possibilities of memory in your AI agent. So we have two examples here travel concierge memories and then life coach memories. So yeah as you see in the second one you'll be collecting tons of information that is valuable for uh yeah for my life. Um and then my dreams, my goals, uh what I was thinking a month ago or a year ago. So the second one is is mostly like super advanced and complex and sophisticated memorable that requires uh lots of scaling uh for sure. Okay. Um so yeah, that was the end of the the question the the Q&A session probably. >> Yeah. >> Okay. Um yeah, and then we can just switch to resources. So um all right, this has been awesome. To wrap things up, um we're we've linked a few great resources here, including the context engineering cookbook, which was referenced, and the context summarization cookbook and our agents Python SDK. I know we've gotten a lot of questions on is this available in GitHub. So you can explore all of these links on the right and the full build hour repo is available on GitHub. Um, so good news. We're likely going to squeeze one or two more of these in before the end of the year. So keep an eye out on our build hours page linked here. And um, a big thank you all so much for tuning in and a big thanks to Emmery who's did an amazing job with this session. >> Yeah, thanks everyone. Uh, we hope you enjoyed uh, this build hour on an agent member patterns. I know we covered like lots of different techniques uh lots of different information about memory, how to think about memory, how to design memory. So, so overall as you see there are too many options but the core uh idea is basically better understanding what your agent should remember and how it should remember and how it should forget. So you can think about these three things when you're designing your own agent u memory. Uh and this is still an evolving field. So you you might see like some um like new features coming uh about memory overall. Uh but yeah, I just wanted to show you like different design tradeoffs uh and and guide you with the with the best option. So finding the right balance between these techniques are uh usually like related to your specific uh use case. And then you can keep track of all of all the news and cookbooks uh in the resources section. So, I'll be also upload uploading this um demo page uh so demo application to to our build hours GitHub. Uh and then yeah, thank you for your time and thank you for for listening uh all of this. >> Yeah, have a great rest of your day and we'll see you next time.",
  "segments": [
    {
      "start": 1.6,
      "end": 5.28,
      "text": "Hi everyone, welcome back to another"
    },
    {
      "start": 3.44,
      "end": 6.88,
      "text": "build hour."
    },
    {
      "start": 5.28,
      "end": 8.64,
      "text": "I'm Michaela on the startup marketing"
    },
    {
      "start": 6.88,
      "end": 11.36,
      "text": "team and I'm here today with two members"
    },
    {
      "start": 8.64,
      "end": 13.44,
      "text": "of our solution architecture team. Emry"
    },
    {
      "start": 11.36,
      "end": 15.28,
      "text": "live in the studio and Brian joining"
    },
    {
      "start": 13.44,
      "end": 16.64,
      "text": "virtually to help address Q&A throughout"
    },
    {
      "start": 15.28,
      "end": 19.04,
      "text": "the hour."
    },
    {
      "start": 16.64,
      "end": 20.8,
      "text": ">> Hi, I'm Emry. I work as a solution"
    },
    {
      "start": 19.04,
      "end": 23.36,
      "text": "architect at OpenAI supporting digital"
    },
    {
      "start": 20.8,
      "end": 25.76,
      "text": "native customers on building various of"
    },
    {
      "start": 23.36,
      "end": 27.36,
      "text": "AI use cases including longunning AI"
    },
    {
      "start": 25.76,
      "end": 29.6,
      "text": "agents."
    },
    {
      "start": 27.36,
      "end": 31.52,
      "text": "So today's topic is agent memory"
    },
    {
      "start": 29.6,
      "end": 36.08,
      "text": "patterns which is a very exciting topic"
    },
    {
      "start": 31.52,
      "end": 38.0,
      "text": "in Emry and I's first ever build hour."
    },
    {
      "start": 36.08,
      "end": 39.6,
      "text": "So if you've been following along, we"
    },
    {
      "start": 38.0,
      "end": 42.16,
      "text": "started with how to build agents from"
    },
    {
      "start": 39.6,
      "end": 45.52,
      "text": "scratch using responses API, then moved"
    },
    {
      "start": 42.16,
      "end": 48.0,
      "text": "into agent RFT and today exploring agent"
    },
    {
      "start": 45.52,
      "end": 49.68,
      "text": "memory patterns. All of the sessions are"
    },
    {
      "start": 48.0,
      "end": 51.12,
      "text": "up on our YouTube channel, so definitely"
    },
    {
      "start": 49.68,
      "end": 54.48,
      "text": "check them out if you want to catch up"
    },
    {
      "start": 51.12,
      "end": 56.8,
      "text": "or revisit earlier builds."
    },
    {
      "start": 54.48,
      "end": 58.8,
      "text": "Though the focus on the build hour is to"
    },
    {
      "start": 56.8,
      "end": 61.76,
      "text": "empower you with the best practices,"
    },
    {
      "start": 58.8,
      "end": 67.44,
      "text": "tools and AI expertise to scale your"
    },
    {
      "start": 61.76,
      "end": 69.44,
      "text": "company using open AI APIs and models."
    },
    {
      "start": 67.44,
      "end": 71.2,
      "text": "So for today's build hour, we'll start"
    },
    {
      "start": 69.44,
      "end": 73.2,
      "text": "with an introduction to context"
    },
    {
      "start": 71.2,
      "end": 75.68,
      "text": "engineering, the foundation for agent"
    },
    {
      "start": 73.2,
      "end": 77.52,
      "text": "memory, and then Emry will walk through"
    },
    {
      "start": 75.68,
      "end": 79.92,
      "text": "several live demos covering memory"
    },
    {
      "start": 77.52,
      "end": 82.24,
      "text": "patterns like reshape and fit, isolate"
    },
    {
      "start": 79.92,
      "end": 84.48,
      "text": "and route, and extract and retrieve."
    },
    {
      "start": 82.24,
      "end": 86.96,
      "text": "We'll end with best practices,"
    },
    {
      "start": 84.48,
      "end": 88.4,
      "text": "resources, and of course, live Q&A. On"
    },
    {
      "start": 86.96,
      "end": 90.48,
      "text": "the right hand side of the screen, you"
    },
    {
      "start": 88.4,
      "end": 92.4,
      "text": "can drop questions into the Q&A box any"
    },
    {
      "start": 90.48,
      "end": 93.76,
      "text": "time during the session. Our team is"
    },
    {
      "start": 92.4,
      "end": 95.44,
      "text": "monitoring both in the room and"
    },
    {
      "start": 93.76,
      "end": 97.52,
      "text": "virtually to help answer throughout, and"
    },
    {
      "start": 95.44,
      "end": 99.76,
      "text": "we'll save a few for the end to go"
    },
    {
      "start": 97.52,
      "end": 103.2,
      "text": "through live. All right, with that, I'll"
    },
    {
      "start": 99.76,
      "end": 106.64,
      "text": "hand it over to Emry to kick things off."
    },
    {
      "start": 103.2,
      "end": 109.76,
      "text": ">> Thanks, Michaela. Hi, everyone. Um so"
    },
    {
      "start": 106.64,
      "end": 111.28,
      "text": "I'll start the first part of this um the"
    },
    {
      "start": 109.76,
      "end": 113.36,
      "text": "session with context engineering"
    },
    {
      "start": 111.28,
      "end": 115.92,
      "text": "definition."
    },
    {
      "start": 113.36,
      "end": 118.64,
      "text": "So this nice definitions from Andre"
    },
    {
      "start": 115.92,
      "end": 120.88,
      "text": "Karpati. I'll start by emphasizing that"
    },
    {
      "start": 118.64,
      "end": 123.92,
      "text": "the context engineering is both an art"
    },
    {
      "start": 120.88,
      "end": 126.64,
      "text": "and a science. So it's art because it"
    },
    {
      "start": 123.92,
      "end": 129.44,
      "text": "involves judgment. So you have to decide"
    },
    {
      "start": 126.64,
      "end": 131.92,
      "text": "what matters most at a given step of uh"
    },
    {
      "start": 129.44,
      "end": 133.68,
      "text": "a reasoning or action processes. It's"
    },
    {
      "start": 131.92,
      "end": 135.92,
      "text": "science because there are concrete"
    },
    {
      "start": 133.68,
      "end": 138.32,
      "text": "patterns, methods, and measurable"
    },
    {
      "start": 135.92,
      "end": 141.36,
      "text": "impacts to make context management more"
    },
    {
      "start": 138.32,
      "end": 143.44,
      "text": "systematic and and repeatable. So, I'll"
    },
    {
      "start": 141.36,
      "end": 145.36,
      "text": "highlight that modern LLMs don't just"
    },
    {
      "start": 143.44,
      "end": 148.24,
      "text": "perform based on the model quality, but"
    },
    {
      "start": 145.36,
      "end": 151.96,
      "text": "they perform based on the context you"
    },
    {
      "start": 148.24,
      "end": 151.96,
      "text": "you give them."
    },
    {
      "start": 152.64,
      "end": 155.76,
      "text": "In this slide, I want to talk about"
    },
    {
      "start": 154.4,
      "end": 157.2,
      "text": "different disciplines that comes"
    },
    {
      "start": 155.76,
      "end": 159.28,
      "text": "together to basically present the"
    },
    {
      "start": 157.2,
      "end": 161.28,
      "text": "context engineering. Uh so it is a"
    },
    {
      "start": 159.28,
      "end": 163.2,
      "text": "broader discipline than any single"
    },
    {
      "start": 161.28,
      "end": 165.76,
      "text": "technique like prompt engineering or or"
    },
    {
      "start": 163.2,
      "end": 167.6,
      "text": "retrieval. So the diagram visually"
    },
    {
      "start": 165.76,
      "end": 170.56,
      "text": "represents the ecosystem of context"
    },
    {
      "start": 167.6,
      "end": 172.24,
      "text": "optimization layers that together shape"
    },
    {
      "start": 170.56,
      "end": 173.68,
      "text": "uh what the model sees and and"
    },
    {
      "start": 172.24,
      "end": 176.64,
      "text": "understands. So you see prompt"
    },
    {
      "start": 173.68,
      "end": 178.8,
      "text": "engineering uh as as a core principle"
    },
    {
      "start": 176.64,
      "end": 181.52,
      "text": "structured output rack state and history"
    },
    {
      "start": 178.8,
      "end": 183.28,
      "text": "management memory is also a crucial"
    },
    {
      "start": 181.52,
      "end": 185.36,
      "text": "part. So using persistent or"
    },
    {
      "start": 183.28,
      "end": 187.28,
      "text": "semi-persistent storage like files,"
    },
    {
      "start": 185.36,
      "end": 189.36,
      "text": "databases or memory tools to upload and"
    },
    {
      "start": 187.28,
      "end": 191.28,
      "text": "retrieve key information"
    },
    {
      "start": 189.36,
      "end": 195.12,
      "text": "and all of this is contained inside the"
    },
    {
      "start": 191.28,
      "end": 197.2,
      "text": "larger sphere of context engineering. Um"
    },
    {
      "start": 195.12,
      "end": 199.36,
      "text": "so we can also connect these"
    },
    {
      "start": 197.2,
      "end": 201.2,
      "text": "capabilities into different uh product"
    },
    {
      "start": 199.36,
      "end": 202.72,
      "text": "capabilities."
    },
    {
      "start": 201.2,
      "end": 205.92,
      "text": "Here"
    },
    {
      "start": 202.72,
      "end": 209.52,
      "text": "is a nice summarization slide um that"
    },
    {
      "start": 205.92,
      "end": 212.24,
      "text": "talks about the the core principles um"
    },
    {
      "start": 209.52,
      "end": 215.52,
      "text": "like why it matters because longunning"
    },
    {
      "start": 212.24,
      "end": 219.04,
      "text": "tools longunning and tool heavy agents"
    },
    {
      "start": 215.52,
      "end": 222.0,
      "text": "blood tokens and degrade quality uh via"
    },
    {
      "start": 219.04,
      "end": 224.72,
      "text": "uh poisoning noise and and and confusion"
    },
    {
      "start": 222.0,
      "end": 226.96,
      "text": "and and bursting. We have three core"
    },
    {
      "start": 224.72,
      "end": 229.44,
      "text": "strategies uh as we discussed in the"
    },
    {
      "start": 226.96,
      "end": 231.76,
      "text": "beginning like reshape and fit uh to the"
    },
    {
      "start": 229.44,
      "end": 233.6,
      "text": "context window, isolate and route the"
    },
    {
      "start": 231.76,
      "end": 236.08,
      "text": "right amount of context to the right"
    },
    {
      "start": 233.6,
      "end": 239.44,
      "text": "agent and extract high quality memories"
    },
    {
      "start": 236.08,
      "end": 241.84,
      "text": "to retrieve uh in the right time. We"
    },
    {
      "start": 239.44,
      "end": 243.68,
      "text": "also have prompt and tool hygiene as a"
    },
    {
      "start": 241.84,
      "end": 247.28,
      "text": "core principle. So keeping system"
    },
    {
      "start": 243.68,
      "end": 249.36,
      "text": "prompts lean, clear and well structured."
    },
    {
      "start": 247.28,
      "end": 251.92,
      "text": "uh use a small canonical set of uh"
    },
    {
      "start": 249.36,
      "end": 254.56,
      "text": "fusion examples and minimize overlap in"
    },
    {
      "start": 251.92,
      "end": 256.56,
      "text": "tools and get the tool selection. And"
    },
    {
      "start": 254.56,
      "end": 258.8,
      "text": "our goal in Northstar is basically"
    },
    {
      "start": 256.56,
      "end": 261.36,
      "text": "aiming for the smallest high signal"
    },
    {
      "start": 258.8,
      "end": 265.36,
      "text": "context that maximize the the likelihood"
    },
    {
      "start": 261.36,
      "end": 267.44,
      "text": "of the desired uh outcome."
    },
    {
      "start": 265.36,
      "end": 269.52,
      "text": "And then in this slide is where our"
    },
    {
      "start": 267.44,
      "end": 272.0,
      "text": "transition from why context injuring"
    },
    {
      "start": 269.52,
      "end": 274.88,
      "text": "matters to how to to actually do it in"
    },
    {
      "start": 272.0,
      "end": 277.84,
      "text": "in practice. So I'll frame this as a"
    },
    {
      "start": 274.88,
      "end": 279.92,
      "text": "toolkit of of techniques. So these are"
    },
    {
      "start": 277.84,
      "end": 281.68,
      "text": "not mutually exclusive. So most real"
    },
    {
      "start": 279.92,
      "end": 284.0,
      "text": "world agent architectures combine"
    },
    {
      "start": 281.68,
      "end": 287.28,
      "text": "multiple strategies depending on the use"
    },
    {
      "start": 284.0,
      "end": 289.52,
      "text": "case uh and the context budget. So the"
    },
    {
      "start": 287.28,
      "end": 291.92,
      "text": "first technique is reshape and fit. We"
    },
    {
      "start": 289.52,
      "end": 294.24,
      "text": "can apply context trimming, compaction"
    },
    {
      "start": 291.92,
      "end": 297.2,
      "text": "and summarization. The second one is"
    },
    {
      "start": 294.24,
      "end": 300.4,
      "text": "isolate and route. uh we can offload"
    },
    {
      "start": 297.2,
      "end": 303.76,
      "text": "context uh and tools to specific sub"
    },
    {
      "start": 300.4,
      "end": 307.52,
      "text": "aents with a selective handoff and the"
    },
    {
      "start": 303.76,
      "end": 310.0,
      "text": "last bucket is extract uh and retrieve"
    },
    {
      "start": 307.52,
      "end": 312.16,
      "text": "um we can talk about memory extraction"
    },
    {
      "start": 310.0,
      "end": 316.08,
      "text": "state management and memory retrieval in"
    },
    {
      "start": 312.16,
      "end": 317.84,
      "text": "in that last um bucket"
    },
    {
      "start": 316.08,
      "end": 320.32,
      "text": "when we talk about context engineing"
    },
    {
      "start": 317.84,
      "end": 322.16,
      "text": "it's essential to distinguish between"
    },
    {
      "start": 320.32,
      "end": 324.56,
      "text": "short-term and long-term memory because"
    },
    {
      "start": 322.16,
      "end": 327.28,
      "text": "they solve very different problems uh I"
    },
    {
      "start": 324.56,
      "end": 330.32,
      "text": "think we group uh the first two bucket"
    },
    {
      "start": 327.28,
      "end": 333.04,
      "text": "as short-term memory which we also call"
    },
    {
      "start": 330.32,
      "end": 335.04,
      "text": "as insession techniques and then the"
    },
    {
      "start": 333.04,
      "end": 337.36,
      "text": "last bucket is long-term memory uh we"
    },
    {
      "start": 335.04,
      "end": 339.68,
      "text": "call it cross session. So that means you"
    },
    {
      "start": 337.36,
      "end": 342.16,
      "text": "can um collect different information"
    },
    {
      "start": 339.68,
      "end": 345.2,
      "text": "from multiple sessions uh and you can"
    },
    {
      "start": 342.16,
      "end": 348.48,
      "text": "retrieve back in in the next session or"
    },
    {
      "start": 345.2,
      "end": 350.0,
      "text": "other sessions uh in in the future. So"
    },
    {
      "start": 348.48,
      "end": 352.56,
      "text": "short-term memory is all about like"
    },
    {
      "start": 350.0,
      "end": 354.64,
      "text": "making the most of the context window uh"
    },
    {
      "start": 352.56,
      "end": 356.4,
      "text": "during an active interaction and active"
    },
    {
      "start": 354.64,
      "end": 359.2,
      "text": "conversation."
    },
    {
      "start": 356.4,
      "end": 361.68,
      "text": "Uh and then in contrast long-term memory"
    },
    {
      "start": 359.2,
      "end": 366.76,
      "text": "is is about building continuity uh"
    },
    {
      "start": 361.68,
      "end": 366.76,
      "text": "across across the the sessions."
    },
    {
      "start": 367.2,
      "end": 372.32,
      "text": "Cool. So we we often get excited about"
    },
    {
      "start": 369.28,
      "end": 373.92,
      "text": "how powerful our agents are becoming how"
    },
    {
      "start": 372.32,
      "end": 376.56,
      "text": "AI models are getting them better and"
    },
    {
      "start": 373.92,
      "end": 378.56,
      "text": "better. They can handle complex tasks uh"
    },
    {
      "start": 376.56,
      "end": 381.6,
      "text": "route between tools. They can plan"
    },
    {
      "start": 378.56,
      "end": 383.28,
      "text": "multi-step workflows. But underneath all"
    },
    {
      "start": 381.6,
      "end": 386.88,
      "text": "that there is a there is a core"
    },
    {
      "start": 383.28,
      "end": 388.64,
      "text": "bottleneck because context is is finite."
    },
    {
      "start": 386.88,
      "end": 390.8,
      "text": "So every piece of information we add to"
    },
    {
      "start": 388.64,
      "end": 393.52,
      "text": "the prompt instructions"
    },
    {
      "start": 390.8,
      "end": 396.16,
      "text": "um conversation history tool outputs"
    },
    {
      "start": 393.52,
      "end": 398.64,
      "text": "competes for a space in in a fixed uh"
    },
    {
      "start": 396.16,
      "end": 401.68,
      "text": "token budget."
    },
    {
      "start": 398.64,
      "end": 403.76,
      "text": "And this is why uh it matters slide. Uh"
    },
    {
      "start": 401.68,
      "end": 405.92,
      "text": "I want to make the problem concrete"
    },
    {
      "start": 403.76,
      "end": 407.68,
      "text": "here. So I'll frame it around before and"
    },
    {
      "start": 405.92,
      "end": 410.88,
      "text": "after contrast. So you see two"
    },
    {
      "start": 407.68,
      "end": 412.64,
      "text": "conversations. Um what happens without"
    },
    {
      "start": 410.88,
      "end": 415.12,
      "text": "memory on the left and what happens with"
    },
    {
      "start": 412.64,
      "end": 418.0,
      "text": "memory on the on the right. So on the"
    },
    {
      "start": 415.12,
      "end": 420.4,
      "text": "left hand side um the user started with"
    },
    {
      "start": 418.0,
      "end": 423.52,
      "text": "the issues like Wi-Fi, battery and over"
    },
    {
      "start": 420.4,
      "end": 425.6,
      "text": "overheating in it troubleshooting agent."
    },
    {
      "start": 423.52,
      "end": 428.08,
      "text": "After many turns the agent has forgotten"
    },
    {
      "start": 425.6,
      "end": 430.64,
      "text": "the earlier context. it falls back to"
    },
    {
      "start": 428.08,
      "end": 433.6,
      "text": "reasking for information that the user"
    },
    {
      "start": 430.64,
      "end": 435.36,
      "text": "already gave. Right? But on the right"
    },
    {
      "start": 433.6,
      "end": 437.92,
      "text": "hand side, the agent remembers the"
    },
    {
      "start": 435.36,
      "end": 440.88,
      "text": "original issues even after many turns."
    },
    {
      "start": 437.92,
      "end": 443.12,
      "text": "It can pick up the unresolved thread. Uh"
    },
    {
      "start": 440.88,
      "end": 445.92,
      "text": "it references previous actions like"
    },
    {
      "start": 443.12,
      "end": 448.0,
      "text": "firmware update, background sync which"
    },
    {
      "start": 445.92,
      "end": 449.92,
      "text": "makes it feel intelligent uh and"
    },
    {
      "start": 448.0,
      "end": 453.04,
      "text": "reliable. So this is such a stateful"
    },
    {
      "start": 449.92,
      "end": 456.6,
      "text": "behavior which is the foundation of uh a"
    },
    {
      "start": 453.04,
      "end": 456.6,
      "text": "longunning agent."
    },
    {
      "start": 456.88,
      "end": 460.48,
      "text": "Now I'll switch gears to to failure"
    },
    {
      "start": 458.88,
      "end": 462.48,
      "text": "mode. So we can group these failure"
    },
    {
      "start": 460.48,
      "end": 465.2,
      "text": "modes into four categories. The first"
    },
    {
      "start": 462.48,
      "end": 467.44,
      "text": "one is context burst. So you can imagine"
    },
    {
      "start": 465.2,
      "end": 469.44,
      "text": "it as a sudden token spike in one of or"
    },
    {
      "start": 467.44,
      "end": 471.84,
      "text": "multiple components"
    },
    {
      "start": 469.44,
      "end": 474.88,
      "text": "um to do the limited external control or"
    },
    {
      "start": 471.84,
      "end": 476.88,
      "text": "increased calls. Context conflict if"
    },
    {
      "start": 474.88,
      "end": 479.92,
      "text": "there's any contradictory instructions"
    },
    {
      "start": 476.88,
      "end": 482.56,
      "text": "or information in your context. Context"
    },
    {
      "start": 479.92,
      "end": 485.36,
      "text": "poisoning uh if there's an incorrect"
    },
    {
      "start": 482.56,
      "end": 487.76,
      "text": "information uh that enters the context"
    },
    {
      "start": 485.36,
      "end": 490.72,
      "text": "and propagates over the turns. It can be"
    },
    {
      "start": 487.76,
      "end": 492.56,
      "text": "via summaries or memory objects, state"
    },
    {
      "start": 490.72,
      "end": 495.36,
      "text": "objects you're injecting into the"
    },
    {
      "start": 492.56,
      "end": 498.64,
      "text": "context. And then finally context noise."
    },
    {
      "start": 495.36,
      "end": 502.16,
      "text": "So you can imagine it as multiple um"
    },
    {
      "start": 498.64,
      "end": 504.96,
      "text": "tool definitions or like way more many"
    },
    {
      "start": 502.16,
      "end": 507.12,
      "text": "many tool definitions uh coming into"
    },
    {
      "start": 504.96,
      "end": 509.36,
      "text": "your context at the same time. This can"
    },
    {
      "start": 507.12,
      "end": 514.44,
      "text": "be redundant or overly similar items. So"
    },
    {
      "start": 509.36,
      "end": 514.44,
      "text": "that can make a noise uh in the context."
    },
    {
      "start": 514.56,
      "end": 520.4,
      "text": "Uh here's a nice um visualization of"
    },
    {
      "start": 518.08,
      "end": 522.88,
      "text": "context burst uh in tool heavy"
    },
    {
      "start": 520.4,
      "end": 525.52,
      "text": "workflows. So you'll see that um there"
    },
    {
      "start": 522.88,
      "end": 527.84,
      "text": "will be like a specific increase uh in"
    },
    {
      "start": 525.52,
      "end": 530.72,
      "text": "one specific turn and you'll be"
    },
    {
      "start": 527.84,
      "end": 533.36,
      "text": "injecting uh like large amount of tool"
    },
    {
      "start": 530.72,
      "end": 535.84,
      "text": "tokens here."
    },
    {
      "start": 533.36,
      "end": 538.72,
      "text": "And then the next one is is context"
    },
    {
      "start": 535.84,
      "end": 540.64,
      "text": "conflict. So we can easily visualize it"
    },
    {
      "start": 538.72,
      "end": 544.48,
      "text": "here. So you can imagine in one of the"
    },
    {
      "start": 540.64,
      "end": 547.04,
      "text": "turns uh there's specific tool call and"
    },
    {
      "start": 544.48,
      "end": 548.8,
      "text": "here in this tool call you see that in"
    },
    {
      "start": 547.04,
      "end": 551.84,
      "text": "the system instructions I never issue a"
    },
    {
      "start": 548.8,
      "end": 553.52,
      "text": "refund if warranty status is not active."
    },
    {
      "start": 551.84,
      "end": 555.84,
      "text": "But in the middle of the turn you're"
    },
    {
      "start": 553.52,
      "end": 558.96,
      "text": "also uh saying that it's eligible refund"
    },
    {
      "start": 555.84,
      "end": 560.96,
      "text": "for VIP customers. But at the end of the"
    },
    {
      "start": 558.96,
      "end": 562.88,
      "text": "turn and and your agent is responding,"
    },
    {
      "start": 560.96,
      "end": 564.96,
      "text": "hey, you know, given your urgent travel,"
    },
    {
      "start": 562.88,
      "end": 568.0,
      "text": "I can issue a full refund. So, this is a"
    },
    {
      "start": 564.96,
      "end": 570.8,
      "text": "nice vis visualization or example for"
    },
    {
      "start": 568.0,
      "end": 572.8,
      "text": "the specific um context conflict that"
    },
    {
      "start": 570.8,
      "end": 576.16,
      "text": "can be coming from uh one of the the"
    },
    {
      "start": 572.8,
      "end": 578.64,
      "text": "tool results."
    },
    {
      "start": 576.16,
      "end": 581.12,
      "text": "And then last one is context poisoning."
    },
    {
      "start": 578.64,
      "end": 583.44,
      "text": "uh so you can imagine it as a"
    },
    {
      "start": 581.12,
      "end": 586.32,
      "text": "hallucination or something inaccurate"
    },
    {
      "start": 583.44,
      "end": 589.6,
      "text": "mixed into the context in any step and"
    },
    {
      "start": 586.32,
      "end": 592.08,
      "text": "propagates across different terms. So"
    },
    {
      "start": 589.6,
      "end": 594.8,
      "text": "here we have a couple possible pitfalls"
    },
    {
      "start": 592.08,
      "end": 597.04,
      "text": "here. Uh losses summarization edits can"
    },
    {
      "start": 594.8,
      "end": 600.24,
      "text": "can be causing this."
    },
    {
      "start": 597.04,
      "end": 602.32,
      "text": "If you're using a free form uh note that"
    },
    {
      "start": 600.24,
      "end": 605.92,
      "text": "accumulates over time that can be"
    },
    {
      "start": 602.32,
      "end": 608.32,
      "text": "contradict and then finally uh older"
    },
    {
      "start": 605.92,
      "end": 610.96,
      "text": "summaries override the newer ones and"
    },
    {
      "start": 608.32,
      "end": 613.12,
      "text": "you'll be basically uh causing any"
    },
    {
      "start": 610.96,
      "end": 615.52,
      "text": "hallucinations uh because of the summary"
    },
    {
      "start": 613.12,
      "end": 617.68,
      "text": "logic and you'll be injecting that"
    },
    {
      "start": 615.52,
      "end": 622.36,
      "text": "hallucination into the into the context"
    },
    {
      "start": 617.68,
      "end": 622.36,
      "text": "and propagating uh over time."
    },
    {
      "start": 622.8,
      "end": 628.8,
      "text": "Cool. Now I'll stop sharing my screen"
    },
    {
      "start": 625.76,
      "end": 631.12,
      "text": "and switch to the demo that I prepared"
    },
    {
      "start": 628.8,
      "end": 634.08,
      "text": "for you."
    },
    {
      "start": 631.12,
      "end": 636.24,
      "text": "Uh and then I'll go over all of these"
    },
    {
      "start": 634.08,
      "end": 638.72,
      "text": "some of these challenges"
    },
    {
      "start": 636.24,
      "end": 643.28,
      "text": "um to show you like how it actually"
    },
    {
      "start": 638.72,
      "end": 646.96,
      "text": "works in a real world scenario. Okay,"
    },
    {
      "start": 643.28,
      "end": 649.96,
      "text": "let me share my screen."
    },
    {
      "start": 646.96,
      "end": 649.96,
      "text": "Cool."
    },
    {
      "start": 650.16,
      "end": 655.2,
      "text": "So here I prepared a demo app for for"
    },
    {
      "start": 653.28,
      "end": 656.88,
      "text": "this build hour. It is an ID"
    },
    {
      "start": 655.2,
      "end": 660.32,
      "text": "troubleshooting agent for software"
    },
    {
      "start": 656.88,
      "end": 663.28,
      "text": "solving issues uh for for issues related"
    },
    {
      "start": 660.32,
      "end": 665.12,
      "text": "to both software and hardware. Uh and"
    },
    {
      "start": 663.28,
      "end": 668.08,
      "text": "this is a dual agent demo that lets you"
    },
    {
      "start": 665.12,
      "end": 670.96,
      "text": "run two agents side by side. So backend"
    },
    {
      "start": 668.08,
      "end": 673.92,
      "text": "logic states inside the nextJS app and"
    },
    {
      "start": 670.96,
      "end": 676.32,
      "text": "I'll be using OpenAI agents SDK."
    },
    {
      "start": 673.92,
      "end": 678.16,
      "text": "So we have two tools connected to to"
    },
    {
      "start": 676.32,
      "end": 681.52,
      "text": "that agent. One of them is get orders"
    },
    {
      "start": 678.16,
      "end": 684.96,
      "text": "and other one is get policy. So here I"
    },
    {
      "start": 681.52,
      "end": 687.28,
      "text": "can start sending a message uh and"
    },
    {
      "start": 684.96,
      "end": 689.68,
      "text": "saying hi to to both of the agents,"
    },
    {
      "start": 687.28,
      "end": 691.76,
      "text": "right? Uh and then you'll see that both"
    },
    {
      "start": 689.68,
      "end": 695.12,
      "text": "of the agents are are responding to my"
    },
    {
      "start": 691.76,
      "end": 697.44,
      "text": "message and then here I can say hey my"
    },
    {
      "start": 695.12,
      "end": 700.48,
      "text": "laptop fan is making weird noises while"
    },
    {
      "start": 697.44,
      "end": 702.48,
      "text": "I playing games. Is it normal? So here"
    },
    {
      "start": 700.48,
      "end": 704.16,
      "text": "you see that the the configuration for"
    },
    {
      "start": 702.48,
      "end": 707.44,
      "text": "both of the agents are same. They're at"
    },
    {
      "start": 704.16,
      "end": 709.12,
      "text": "the same model, same reasoning level. um"
    },
    {
      "start": 707.44,
      "end": 712.56,
      "text": "but I'm sending the same message and"
    },
    {
      "start": 709.12,
      "end": 715.92,
      "text": "there is no memory um basically there is"
    },
    {
      "start": 712.56,
      "end": 718.08,
      "text": "no memory configuration yet. So here you"
    },
    {
      "start": 715.92,
      "end": 719.84,
      "text": "also see the context usage bars at the"
    },
    {
      "start": 718.08,
      "end": 722.72,
      "text": "at the top. So you're you're seeing"
    },
    {
      "start": 719.84,
      "end": 726.56,
      "text": "different type of components uh that is"
    },
    {
      "start": 722.72,
      "end": 728.64,
      "text": "already in the context now. Um and I can"
    },
    {
      "start": 726.56,
      "end": 732.24,
      "text": "say hey before I want to see my orders"
    },
    {
      "start": 728.64,
      "end": 735.68,
      "text": "my order number is 1 2 3 uh four five"
    },
    {
      "start": 732.24,
      "end": 738.96,
      "text": "and so now I'm expecting the model to to"
    },
    {
      "start": 735.68,
      "end": 742.48,
      "text": "make a tool call and show me uh the"
    },
    {
      "start": 738.96,
      "end": 745.28,
      "text": "orders I have. So here you see that the"
    },
    {
      "start": 742.48,
      "end": 748.64,
      "text": "order status the items I have and it's"
    },
    {
      "start": 745.28,
      "end": 751.92,
      "text": "powered by a specific tool called. So as"
    },
    {
      "start": 748.64,
      "end": 753.84,
      "text": "you see over time um it will"
    },
    {
      "start": 751.92,
      "end": 755.88,
      "text": "accumulating different tokens and"
    },
    {
      "start": 753.84,
      "end": 757.04,
      "text": "different type of tokens here and"
    },
    {
      "start": 755.88,
      "end": 759.36,
      "text": "[clears throat] in the context life"
    },
    {
      "start": 757.04,
      "end": 762.48,
      "text": "cycles I'm visualizing what is happening"
    },
    {
      "start": 759.36,
      "end": 765.6,
      "text": "under the hood across multiple turns. So"
    },
    {
      "start": 762.48,
      "end": 768.96,
      "text": "here you see that I have uh 84 tokens of"
    },
    {
      "start": 765.6,
      "end": 771.92,
      "text": "system instructions. My user input is"
    },
    {
      "start": 768.96,
      "end": 775.36,
      "text": "increasing uh slowly. Uh but the core"
    },
    {
      "start": 771.92,
      "end": 780.08,
      "text": "component here uh is agent output that"
    },
    {
      "start": 775.36,
      "end": 782.72,
      "text": "will be generated by by a model."
    },
    {
      "start": 780.08,
      "end": 785.36,
      "text": "Cool. Um so this is a typical real world"
    },
    {
      "start": 782.72,
      "end": 788.88,
      "text": "scenario. So now I also want to showcase"
    },
    {
      "start": 785.36,
      "end": 792.96,
      "text": "like how context burst is is happening."
    },
    {
      "start": 788.88,
      "end": 796.48,
      "text": "So I can still uh start with high um and"
    },
    {
      "start": 792.96,
      "end": 799.28,
      "text": "I can say hey this time I'm having an"
    },
    {
      "start": 796.48,
      "end": 802.88,
      "text": "overheating issue on my laptop"
    },
    {
      "start": 799.28,
      "end": 805.28,
      "text": "uh and then the model is responding to"
    },
    {
      "start": 802.88,
      "end": 807.76,
      "text": "to my to my message to my issue"
    },
    {
      "start": 805.28,
      "end": 810.8,
      "text": "basically uh and then here it's telling"
    },
    {
      "start": 807.76,
      "end": 812.48,
      "text": "me like specific um instructions and"
    },
    {
      "start": 810.8,
      "end": 815.52,
      "text": "it's asking me some questions to better"
    },
    {
      "start": 812.48,
      "end": 817.52,
      "text": "understand uh what's happening right and"
    },
    {
      "start": 815.52,
      "end": 819.68,
      "text": "then I can say hey thanks before that I"
    },
    {
      "start": 817.52,
      "end": 822.8,
      "text": "want to see the refund policy of my"
    },
    {
      "start": 819.68,
      "end": 824.64,
      "text": "MacBook Pro 2014."
    },
    {
      "start": 822.8,
      "end": 827.04,
      "text": "So while I'm sending this message, I"
    },
    {
      "start": 824.64,
      "end": 830.64,
      "text": "also want to quickly show you the code"
    },
    {
      "start": 827.04,
      "end": 833.92,
      "text": "and core concept of or how it's working."
    },
    {
      "start": 830.64,
      "end": 836.8,
      "text": "So it's powered by open agent SDK and"
    },
    {
      "start": 833.92,
      "end": 839.52,
      "text": "here you see um the agent definition. So"
    },
    {
      "start": 836.8,
      "end": 843.6,
      "text": "it's a customer support assistant. Uh"
    },
    {
      "start": 839.52,
      "end": 846.08,
      "text": "I'm having specific instructions here um"
    },
    {
      "start": 843.6,
      "end": 848.88,
      "text": "that I'm adding. Uh I'm using like"
    },
    {
      "start": 846.08,
      "end": 850.56,
      "text": "different models here. Um, and also I"
    },
    {
      "start": 848.88,
      "end": 852.24,
      "text": "can show you the system prompt really"
    },
    {
      "start": 850.56,
      "end": 855.24,
      "text": "quickly"
    },
    {
      "start": 852.24,
      "end": 855.24,
      "text": "instructions."
    },
    {
      "start": 855.52,
      "end": 859.84,
      "text": "Um, so it's basically I'm I'm saying"
    },
    {
      "start": 858.08,
      "end": 863.76,
      "text": "that hey you you're a customer support"
    },
    {
      "start": 859.84,
      "end": 866.56,
      "text": "assistant for for devices. Uh, and then"
    },
    {
      "start": 863.76,
      "end": 869.68,
      "text": "I'm using like very slight prompting and"
    },
    {
      "start": 866.56,
      "end": 874.24,
      "text": "instructions for for that specific uh"
    },
    {
      "start": 869.68,
      "end": 877.04,
      "text": "agent here. So let's go back to um the"
    },
    {
      "start": 874.24,
      "end": 879.76,
      "text": "response. So, since I asked about the"
    },
    {
      "start": 877.04,
      "end": 882.16,
      "text": "the specific refund policy for from a"
    },
    {
      "start": 879.76,
      "end": 885.44,
      "text": "MacBook Pro 2014,"
    },
    {
      "start": 882.16,
      "end": 888.8,
      "text": "uh it's made a tool call get refund and"
    },
    {
      "start": 885.44,
      "end": 893.04,
      "text": "it's basically returning uh a specific"
    },
    {
      "start": 888.8,
      "end": 895.68,
      "text": "um refund policy that I added before."
    },
    {
      "start": 893.04,
      "end": 898.0,
      "text": "So, here you see that in between turn"
    },
    {
      "start": 895.68,
      "end": 902.08,
      "text": "two and turn three there is a specific"
    },
    {
      "start": 898.0,
      "end": 905.12,
      "text": "spike um in the in the context window."
    },
    {
      "start": 902.08,
      "end": 908.8,
      "text": "So, in turn two, I I I had maybe around"
    },
    {
      "start": 905.12,
      "end": 911.52,
      "text": "like 300 400 tokens, but now I have more"
    },
    {
      "start": 908.8,
      "end": 913.6,
      "text": "than 3,000 tokens because I am just"
    },
    {
      "start": 911.52,
      "end": 916.56,
      "text": "dumping lots of information into the"
    },
    {
      "start": 913.6,
      "end": 921.52,
      "text": "context. And then this is a nice example"
    },
    {
      "start": 916.56,
      "end": 923.6,
      "text": "for for context burst here. um"
    },
    {
      "start": 921.52,
      "end": 926.8,
      "text": "instead of maybe just dumping all of"
    },
    {
      "start": 923.6,
      "end": 929.52,
      "text": "these information into the context uh as"
    },
    {
      "start": 926.8,
      "end": 931.84,
      "text": "as a refund policy, I can be more"
    },
    {
      "start": 929.52,
      "end": 935.12,
      "text": "careful about my tool definitions and"
    },
    {
      "start": 931.84,
      "end": 937.2,
      "text": "tool outputs um to basically make a"
    },
    {
      "start": 935.12,
      "end": 939.52,
      "text": "decision about like what should I inject"
    },
    {
      "start": 937.2,
      "end": 942.4,
      "text": "into the context. So maybe not all of"
    },
    {
      "start": 939.52,
      "end": 944.32,
      "text": "these information are are valuable, but"
    },
    {
      "start": 942.4,
      "end": 947.36,
      "text": "as you see that I'll be injecting lots"
    },
    {
      "start": 944.32,
      "end": 949.76,
      "text": "of information into the context that's"
    },
    {
      "start": 947.36,
      "end": 952.88,
      "text": "visualized here uh in this context life"
    },
    {
      "start": 949.76,
      "end": 956.08,
      "text": "cycle tab."
    },
    {
      "start": 952.88,
      "end": 960.56,
      "text": "Cool. Now I'll stop sharing my screen"
    },
    {
      "start": 956.08,
      "end": 966.68,
      "text": "and go back to to the deck. So I'll"
    },
    {
      "start": 960.56,
      "end": 966.68,
      "text": "continue uh with the next uh steps here."
    },
    {
      "start": 968.0,
      "end": 973.76,
      "text": "Okay,"
    },
    {
      "start": 970.88,
      "end": 975.68,
      "text": "nice. So, we talked about challenges and"
    },
    {
      "start": 973.76,
      "end": 977.68,
      "text": "what's going on under the hood and a"
    },
    {
      "start": 975.68,
      "end": 980.56,
      "text": "specific example about context. So, now"
    },
    {
      "start": 977.68,
      "end": 983.28,
      "text": "let's talk about the solution, right? Um"
    },
    {
      "start": 980.56,
      "end": 985.6,
      "text": "so the solution is basically uh managing"
    },
    {
      "start": 983.28,
      "end": 989.28,
      "text": "context efficiently using different"
    },
    {
      "start": 985.6,
      "end": 992.72,
      "text": "techniques such as um tming compaction"
    },
    {
      "start": 989.28,
      "end": 997.2,
      "text": "uh state management memories and make"
    },
    {
      "start": 992.72,
      "end": 998.72,
      "text": "the natural step beyond prompt engineer."
    },
    {
      "start": 997.2,
      "end": 1000.8,
      "text": "Uh again this is also another"
    },
    {
      "start": 998.72,
      "end": 1003.28,
      "text": "visualization about different components"
    },
    {
      "start": 1000.8,
      "end": 1006.16,
      "text": "in the context. Uh so you see that"
    },
    {
      "start": 1003.28,
      "end": 1007.84,
      "text": "across the times it's increasing the"
    },
    {
      "start": 1006.16,
      "end": 1009.68,
      "text": "token counts are increasing and these"
    },
    {
      "start": 1007.84,
      "end": 1011.84,
      "text": "these tokens can be coming from the"
    },
    {
      "start": 1009.68,
      "end": 1014.72,
      "text": "system message user message maybe you"
    },
    {
      "start": 1011.84,
      "end": 1016.8,
      "text": "might be injecting uh memories or maybe"
    },
    {
      "start": 1014.72,
      "end": 1018.88,
      "text": "you might be injecting different uh type"
    },
    {
      "start": 1016.8,
      "end": 1021.84,
      "text": "of specific tokens that can be added"
    },
    {
      "start": 1018.88,
      "end": 1025.76,
      "text": "into your context."
    },
    {
      "start": 1021.84,
      "end": 1027.84,
      "text": "Uh here I want to group uh AI agents in"
    },
    {
      "start": 1025.76,
      "end": 1029.92,
      "text": "terms of context profiles. So we can"
    },
    {
      "start": 1027.84,
      "end": 1032.32,
      "text": "group them into three categories. So"
    },
    {
      "start": 1029.92,
      "end": 1035.12,
      "text": "first one is rack heavy assistance. So"
    },
    {
      "start": 1032.32,
      "end": 1038.0,
      "text": "you can imagine reports policy QA"
    },
    {
      "start": 1035.12,
      "end": 1040.56,
      "text": "agents. Um in these type of agents"
    },
    {
      "start": 1038.0,
      "end": 1042.88,
      "text": "context is most dominated by retrieved"
    },
    {
      "start": 1040.56,
      "end": 1045.52,
      "text": "knowledge and citations. The second one"
    },
    {
      "start": 1042.88,
      "end": 1047.92,
      "text": "is tool heavy workflows. Uh context is"
    },
    {
      "start": 1045.52,
      "end": 1050.56,
      "text": "mostly dominated by frequent tool calls"
    },
    {
      "start": 1047.92,
      "end": 1052.72,
      "text": "and returned payloads. And last one is"
    },
    {
      "start": 1050.56,
      "end": 1056.16,
      "text": "conversational concier. So you can think"
    },
    {
      "start": 1052.72,
      "end": 1058.08,
      "text": "about planning agents, coaching agents."
    },
    {
      "start": 1056.16,
      "end": 1061.2,
      "text": "uh and in this case context is mostly"
    },
    {
      "start": 1058.08,
      "end": 1063.92,
      "text": "dominated by uh growing dialogue"
    },
    {
      "start": 1061.2,
      "end": 1065.6,
      "text": "history. There'll be lots of tokens in"
    },
    {
      "start": 1063.92,
      "end": 1068.24,
      "text": "conversation history like assistant"
    },
    {
      "start": 1065.6,
      "end": 1071.52,
      "text": "usage tokens that scales with uh with"
    },
    {
      "start": 1068.24,
      "end": 1073.84,
      "text": "session lengths"
    },
    {
      "start": 1071.52,
      "end": 1076.96,
      "text": "and then to better understand the the"
    },
    {
      "start": 1073.84,
      "end": 1079.76,
      "text": "solution and uh the techniques uh we can"
    },
    {
      "start": 1076.96,
      "end": 1083.6,
      "text": "go over what is fixed in our context and"
    },
    {
      "start": 1079.76,
      "end": 1084.96,
      "text": "what is dynamic and and a variable. So"
    },
    {
      "start": 1083.6,
      "end": 1086.32,
      "text": "here you see different type of"
    },
    {
      "start": 1084.96,
      "end": 1088.48,
      "text": "components like usually system"
    },
    {
      "start": 1086.32,
      "end": 1091.2,
      "text": "instructions tool definitions and"
    },
    {
      "start": 1088.48,
      "end": 1093.04,
      "text": "examples unless you're doing a rack uh"
    },
    {
      "start": 1091.2,
      "end": 1095.76,
      "text": "approach is is mostly static in the"
    },
    {
      "start": 1093.04,
      "end": 1098.72,
      "text": "context. What is dynamic is is tool"
    },
    {
      "start": 1095.76,
      "end": 1101.68,
      "text": "results retrieved knowledge memories and"
    },
    {
      "start": 1098.72,
      "end": 1105.36,
      "text": "and conversation history. So these are"
    },
    {
      "start": 1101.68,
      "end": 1109.36,
      "text": "the nice examples for dynamic u and"
    },
    {
      "start": 1105.36,
      "end": 1111.6,
      "text": "static context and tokens. uh so you"
    },
    {
      "start": 1109.36,
      "end": 1113.92,
      "text": "have a control on dynamic tokens and you"
    },
    {
      "start": 1111.6,
      "end": 1117.44,
      "text": "can apply different techniques to to"
    },
    {
      "start": 1113.92,
      "end": 1119.04,
      "text": "control it efficiently."
    },
    {
      "start": 1117.44,
      "end": 1121.52,
      "text": "So I would like to start with prompting"
    },
    {
      "start": 1119.04,
      "end": 1124.24,
      "text": "best practices to aid avoid context"
    },
    {
      "start": 1121.52,
      "end": 1125.92,
      "text": "conflict here. Um you can also find it"
    },
    {
      "start": 1124.24,
      "end": 1128.56,
      "text": "from our our prompting guides and"
    },
    {
      "start": 1125.92,
      "end": 1130.96,
      "text": "cookbooks. Uh the first rule is being"
    },
    {
      "start": 1128.56,
      "end": 1132.64,
      "text": "explicit and structured. We suggest you"
    },
    {
      "start": 1130.96,
      "end": 1135.6,
      "text": "to use clear direct language and"
    },
    {
      "start": 1132.64,
      "end": 1137.36,
      "text": "specific enough to to guide action. uh"
    },
    {
      "start": 1135.6,
      "end": 1138.96,
      "text": "you should give room for planning and"
    },
    {
      "start": 1137.36,
      "end": 1140.96,
      "text": "self-reflection. I think this is"
    },
    {
      "start": 1138.96,
      "end": 1143.92,
      "text": "becoming more and more important with uh"
    },
    {
      "start": 1140.96,
      "end": 1146.0,
      "text": "reasoning models like GPT5. Uh and you"
    },
    {
      "start": 1143.92,
      "end": 1149.12,
      "text": "should avoid conflicts. So keep the tool"
    },
    {
      "start": 1146.0,
      "end": 1152.16,
      "text": "set small and non-over overlapping."
    },
    {
      "start": 1149.12,
      "end": 1154.0,
      "text": "Don't use uh ambiguous uh definitions."
    },
    {
      "start": 1152.16,
      "end": 1155.76,
      "text": "Even if a human can pick a tool, the"
    },
    {
      "start": 1154.0,
      "end": 1157.76,
      "text": "model won't either. So be careful with"
    },
    {
      "start": 1155.76,
      "end": 1159.76,
      "text": "conflicting instructions and and tool"
    },
    {
      "start": 1157.76,
      "end": 1162.56,
      "text": "definitions."
    },
    {
      "start": 1159.76,
      "end": 1165.04,
      "text": "So for context noise, we talked about"
    },
    {
      "start": 1162.56,
      "end": 1167.84,
      "text": "like many many tool definitions and many"
    },
    {
      "start": 1165.04,
      "end": 1169.76,
      "text": "tools attached into the context as as an"
    },
    {
      "start": 1167.84,
      "end": 1171.76,
      "text": "example situation."
    },
    {
      "start": 1169.76,
      "end": 1175.28,
      "text": "Um again, you you should be explicit and"
    },
    {
      "start": 1171.76,
      "end": 1177.36,
      "text": "structured in your prompts. Um more"
    },
    {
      "start": 1175.28,
      "end": 1181.04,
      "text": "tools isn't always equal to to better"
    },
    {
      "start": 1177.36,
      "end": 1183.84,
      "text": "outcomes. Uh so favor targeted tools"
    },
    {
      "start": 1181.04,
      "end": 1185.92,
      "text": "with clear tool decision boundaries and"
    },
    {
      "start": 1183.84,
      "end": 1189.2,
      "text": "then return meaningful context from your"
    },
    {
      "start": 1185.92,
      "end": 1192.8,
      "text": "tools. So in the demo um you show that"
    },
    {
      "start": 1189.2,
      "end": 1195.12,
      "text": "specific uh example of context burst. So"
    },
    {
      "start": 1192.8,
      "end": 1197.76,
      "text": "we suggest you to control basically what"
    },
    {
      "start": 1195.12,
      "end": 1201.2,
      "text": "is the tool output uh and then return"
    },
    {
      "start": 1197.76,
      "end": 1203.6,
      "text": "high signal semantically useful fields"
    },
    {
      "start": 1201.2,
      "end": 1206.6,
      "text": "um and prefer human readable uh"
    },
    {
      "start": 1203.6,
      "end": 1206.6,
      "text": "identifiers."
    },
    {
      "start": 1207.52,
      "end": 1212.32,
      "text": "Nice. So now I'll switch gears to"
    },
    {
      "start": 1210.32,
      "end": 1214.56,
      "text": "engineering techniques and I'll start"
    },
    {
      "start": 1212.32,
      "end": 1217.76,
      "text": "with the first one which is reshape and"
    },
    {
      "start": 1214.56,
      "end": 1220.72,
      "text": "fit. So the first technique here is"
    },
    {
      "start": 1217.76,
      "end": 1222.88,
      "text": "context trimming. So it is a pretty"
    },
    {
      "start": 1220.72,
      "end": 1225.12,
      "text": "basic technique. It basically means that"
    },
    {
      "start": 1222.88,
      "end": 1229.2,
      "text": "dropping older turns while keeping the"
    },
    {
      "start": 1225.12,
      "end": 1232.0,
      "text": "last uh end turns. Uh here in the turn"
    },
    {
      "start": 1229.2,
      "end": 1233.76,
      "text": "we have like limited context. Uh it's"
    },
    {
      "start": 1232.0,
      "end": 1235.44,
      "text": "getting getting noisy. There are lots of"
    },
    {
      "start": 1233.76,
      "end": 1237.44,
      "text": "information in the context. It can be"
    },
    {
      "start": 1235.44,
      "end": 1239.68,
      "text": "coming from a tool user message or"
    },
    {
      "start": 1237.44,
      "end": 1242.08,
      "text": "different sources. And there's higher"
    },
    {
      "start": 1239.68,
      "end": 1244.88,
      "text": "likelihood of losing track because uh we"
    },
    {
      "start": 1242.08,
      "end": 1247.76,
      "text": "are getting close to to context limit."
    },
    {
      "start": 1244.88,
      "end": 1250.16,
      "text": "But once we trim the older uh"
    },
    {
      "start": 1247.76,
      "end": 1252.24,
      "text": "conversations, older messages uh now we"
    },
    {
      "start": 1250.16,
      "end": 1254.96,
      "text": "have fresh context. It has better"
    },
    {
      "start": 1252.24,
      "end": 1257.28,
      "text": "attention uh and you'll see that uh it"
    },
    {
      "start": 1254.96,
      "end": 1259.12,
      "text": "will also increase the latency uh that"
    },
    {
      "start": 1257.28,
      "end": 1261.28,
      "text": "you're using."
    },
    {
      "start": 1259.12,
      "end": 1263.92,
      "text": "So it basically keeps the last end"
    },
    {
      "start": 1261.28,
      "end": 1265.84,
      "text": "messages and trips the the previous"
    },
    {
      "start": 1263.92,
      "end": 1268.16,
      "text": "older messages. Uh and these are the"
    },
    {
      "start": 1265.84,
      "end": 1271.36,
      "text": "some parameters and knob we have control"
    },
    {
      "start": 1268.16,
      "end": 1272.64,
      "text": "over in in context trimming."
    },
    {
      "start": 1271.36,
      "end": 1275.52,
      "text": "The second technique is context"
    },
    {
      "start": 1272.64,
      "end": 1278.48,
      "text": "compaction. uh it basically means just"
    },
    {
      "start": 1275.52,
      "end": 1280.56,
      "text": "dropping tool calls or tool call results"
    },
    {
      "start": 1278.48,
      "end": 1282.96,
      "text": "from the older terms while keeping the"
    },
    {
      "start": 1280.56,
      "end": 1285.68,
      "text": "rest of the messages. So if you have a"
    },
    {
      "start": 1282.96,
      "end": 1288.56,
      "text": "tool heavy agent, you can consider these"
    },
    {
      "start": 1285.68,
      "end": 1290.32,
      "text": "techniques. Um you'll see that your"
    },
    {
      "start": 1288.56,
      "end": 1292.56,
      "text": "context will be most dominated by tool"
    },
    {
      "start": 1290.32,
      "end": 1294.4,
      "text": "results. It will be noisy. There will be"
    },
    {
      "start": 1292.56,
      "end": 1297.12,
      "text": "maybe some context noise and lots of"
    },
    {
      "start": 1294.4,
      "end": 1299.2,
      "text": "information coming from different tools."
    },
    {
      "start": 1297.12,
      "end": 1301.52,
      "text": "And after compaction you'll see that"
    },
    {
      "start": 1299.2,
      "end": 1305.12,
      "text": "there will be fresh context uh better"
    },
    {
      "start": 1301.52,
      "end": 1306.88,
      "text": "attention and and faster uh processing"
    },
    {
      "start": 1305.12,
      "end": 1310.08,
      "text": "uh and you will also be keeping the tool"
    },
    {
      "start": 1306.88,
      "end": 1313.36,
      "text": "placeholders uh intact after even after"
    },
    {
      "start": 1310.08,
      "end": 1315.44,
      "text": "the context compaction here"
    },
    {
      "start": 1313.36,
      "end": 1318.4,
      "text": "and a question you might have uh would"
    },
    {
      "start": 1315.44,
      "end": 1320.96,
      "text": "be like okay how can I decide heristics"
    },
    {
      "start": 1318.4,
      "end": 1322.4,
      "text": "about trimming and compaction"
    },
    {
      "start": 1320.96,
      "end": 1325.12,
      "text": "uh so here I can share a couple"
    },
    {
      "start": 1322.4,
      "end": 1328.16,
      "text": "suggestions so first you can you can"
    },
    {
      "start": 1325.12,
      "end": 1330.48,
      "text": "analyze your sessions uh you can collect"
    },
    {
      "start": 1328.16,
      "end": 1333.28,
      "text": "like context snapshots from from"
    },
    {
      "start": 1330.48,
      "end": 1335.28,
      "text": "production or from your users. You can"
    },
    {
      "start": 1333.28,
      "end": 1337.92,
      "text": "collect times down and dislike context"
    },
    {
      "start": 1335.28,
      "end": 1339.52,
      "text": "to see what's going wrong there. Think"
    },
    {
      "start": 1337.92,
      "end": 1341.92,
      "text": "about the average token size of a"
    },
    {
      "start": 1339.52,
      "end": 1346.24,
      "text": "context. Uh what type of task do you"
    },
    {
      "start": 1341.92,
      "end": 1348.8,
      "text": "have in one session? Secondly, um like"
    },
    {
      "start": 1346.24,
      "end": 1350.88,
      "text": "do not trim mid turn and break turn"
    },
    {
      "start": 1348.8,
      "end": 1353.6,
      "text": "blocks. So a turn basically means that a"
    },
    {
      "start": 1350.88,
      "end": 1356.4,
      "text": "user message and all the other message"
    },
    {
      "start": 1353.6,
      "end": 1359.28,
      "text": "until the next user message, right? Uh"
    },
    {
      "start": 1356.4,
      "end": 1361.04,
      "text": "so if you just break or or don't respect"
    },
    {
      "start": 1359.28,
      "end": 1363.84,
      "text": "these turns uh there will be higher"
    },
    {
      "start": 1361.04,
      "end": 1365.84,
      "text": "likelihood of losing track. And then"
    },
    {
      "start": 1363.84,
      "end": 1369.28,
      "text": "finally don't wait to hit context window"
    },
    {
      "start": 1365.84,
      "end": 1371.84,
      "text": "limits. Uh so keep track of of context"
    },
    {
      "start": 1369.28,
      "end": 1374.48,
      "text": "allocation. You can set thresholds like"
    },
    {
      "start": 1371.84,
      "end": 1377.76,
      "text": "40 or 80%. So if you're getting closer"
    },
    {
      "start": 1374.48,
      "end": 1380.32,
      "text": "to hitting the context window limits, uh"
    },
    {
      "start": 1377.76,
      "end": 1383.28,
      "text": "these thresholds will help you to to"
    },
    {
      "start": 1380.32,
      "end": 1386.0,
      "text": "better understand basically uh when you"
    },
    {
      "start": 1383.28,
      "end": 1388.48,
      "text": "should trigger some of these operations."
    },
    {
      "start": 1386.0,
      "end": 1390.4,
      "text": "You can control tool outputs uh and you"
    },
    {
      "start": 1388.48,
      "end": 1392.16,
      "text": "can also keep track of token saves. So"
    },
    {
      "start": 1390.4,
      "end": 1396.08,
      "text": "these techniques are also really nice"
    },
    {
      "start": 1392.16,
      "end": 1398.56,
      "text": "for for cost um cost reducing cost"
    },
    {
      "start": 1396.08,
      "end": 1400.16,
      "text": "purposes. Uh, and you can always keep"
    },
    {
      "start": 1398.56,
      "end": 1402.8,
      "text": "track of like how much token you're"
    },
    {
      "start": 1400.16,
      "end": 1407.76,
      "text": "saving while you're increasing the the"
    },
    {
      "start": 1402.8,
      "end": 1409.6,
      "text": "overall capability of the of your agent."
    },
    {
      "start": 1407.76,
      "end": 1412.48,
      "text": "And then the next technique we have is"
    },
    {
      "start": 1409.6,
      "end": 1414.08,
      "text": "context summarization. Um, so it"
    },
    {
      "start": 1412.48,
      "end": 1417.2,
      "text": "basically means compressing prior"
    },
    {
      "start": 1414.08,
      "end": 1420.64,
      "text": "messages into structured summaries and"
    },
    {
      "start": 1417.2,
      "end": 1423.44,
      "text": "you can inject into the context history."
    },
    {
      "start": 1420.64,
      "end": 1426.88,
      "text": "So here uh in turn n you see lots of"
    },
    {
      "start": 1423.44,
      "end": 1428.96,
      "text": "messages uh like noisy context again and"
    },
    {
      "start": 1426.88,
      "end": 1431.28,
      "text": "you're basically keeping the last n"
    },
    {
      "start": 1428.96,
      "end": 1434.8,
      "text": "messages and just summarizing or"
    },
    {
      "start": 1431.28,
      "end": 1437.52,
      "text": "compressing the previous ones um so that"
    },
    {
      "start": 1434.8,
      "end": 1439.84,
      "text": "you'll have fresh context uh better"
    },
    {
      "start": 1437.52,
      "end": 1441.12,
      "text": "attention faster processing and at the"
    },
    {
      "start": 1439.84,
      "end": 1443.6,
      "text": "end of the day you'll have a golden"
    },
    {
      "start": 1441.12,
      "end": 1445.84,
      "text": "summary. So this will be like a a"
    },
    {
      "start": 1443.6,
      "end": 1447.2,
      "text": "valuable information because you'll be"
    },
    {
      "start": 1445.84,
      "end": 1450.56,
      "text": "basically compressing all of the"
    },
    {
      "start": 1447.2,
      "end": 1453.44,
      "text": "valuable informations. Uh and at the end"
    },
    {
      "start": 1450.56,
      "end": 1456.64,
      "text": "of today it will have like a very dense"
    },
    {
      "start": 1453.44,
      "end": 1458.16,
      "text": "um object that you can keep track of and"
    },
    {
      "start": 1456.64,
      "end": 1460.48,
      "text": "that will be also useful for you to"
    },
    {
      "start": 1458.16,
      "end": 1463.48,
      "text": "better understand what happened in the"
    },
    {
      "start": 1460.48,
      "end": 1463.48,
      "text": "conversation."
    },
    {
      "start": 1463.68,
      "end": 1468.88,
      "text": "And here's a nice visualization uh in"
    },
    {
      "start": 1466.24,
      "end": 1470.8,
      "text": "the context life cycle uh about the"
    },
    {
      "start": 1468.88,
      "end": 1473.2,
      "text": "summarization. So let's say you perform"
    },
    {
      "start": 1470.8,
      "end": 1476.4,
      "text": "the summarization a specific turn. So"
    },
    {
      "start": 1473.2,
      "end": 1478.24,
      "text": "you'll see that you are compressing uh"
    },
    {
      "start": 1476.4,
      "end": 1481.84,
      "text": "all the previous information and"
    },
    {
      "start": 1478.24,
      "end": 1483.92,
      "text": "injecting it back uh into as into the"
    },
    {
      "start": 1481.84,
      "end": 1486.72,
      "text": "context as as a memory object. So you"
    },
    {
      "start": 1483.92,
      "end": 1488.96,
      "text": "see there is a new component um called"
    },
    {
      "start": 1486.72,
      "end": 1491.96,
      "text": "as memory after the summarization"
    },
    {
      "start": 1488.96,
      "end": 1491.96,
      "text": "performed."
    },
    {
      "start": 1493.04,
      "end": 1498.72,
      "text": "Nice. Um so here here is a comparison of"
    },
    {
      "start": 1496.24,
      "end": 1500.16,
      "text": "summarization versus trimming. Uh so"
    },
    {
      "start": 1498.72,
      "end": 1502.32,
      "text": "there are different dimensions that you"
    },
    {
      "start": 1500.16,
      "end": 1505.28,
      "text": "can consider while you're designing uh a"
    },
    {
      "start": 1502.32,
      "end": 1508.88,
      "text": "memory pattern for your for your agent."
    },
    {
      "start": 1505.28,
      "end": 1510.56,
      "text": "Um you can see that in trimming uh"
    },
    {
      "start": 1508.88,
      "end": 1512.24,
      "text": "you'll just keep last entrance and"
    },
    {
      "start": 1510.56,
      "end": 1514.0,
      "text": "you'll be dropping the oldest ones. So"
    },
    {
      "start": 1512.24,
      "end": 1516.8,
      "text": "basically it'll be pretty"
    },
    {
      "start": 1514.0,
      "end": 1519.12,
      "text": "straightforward operation. So it'll be"
    },
    {
      "start": 1516.8,
      "end": 1522.0,
      "text": "very fast uh you know and there's no no"
    },
    {
      "start": 1519.12,
      "end": 1524.32,
      "text": "latency. Uh but the trade-off is that"
    },
    {
      "start": 1522.0,
      "end": 1526.48,
      "text": "you you might be losing some information"
    },
    {
      "start": 1524.32,
      "end": 1528.48,
      "text": "uh that is already there. So I think"
    },
    {
      "start": 1526.48,
      "end": 1531.36,
      "text": "this is the main main trade-off that we"
    },
    {
      "start": 1528.48,
      "end": 1535.92,
      "text": "have. Uh it's it's really best for tool"
    },
    {
      "start": 1531.36,
      "end": 1538.08,
      "text": "heavy ops and and short uh workflows."
    },
    {
      "start": 1535.92,
      "end": 1540.32,
      "text": "And then in in summarizing, you're"
    },
    {
      "start": 1538.08,
      "end": 1542.0,
      "text": "basically just keeping track of all the"
    },
    {
      "start": 1540.32,
      "end": 1544.8,
      "text": "information. So you you're not throwing"
    },
    {
      "start": 1542.0,
      "end": 1547.92,
      "text": "away any anything. Uh this can add this"
    },
    {
      "start": 1544.8,
      "end": 1549.6,
      "text": "can add a little bit of um latency and"
    },
    {
      "start": 1547.92,
      "end": 1552.56,
      "text": "cost because you'll be doing another"
    },
    {
      "start": 1549.6,
      "end": 1553.92,
      "text": "summarization call to a model. Uh but"
    },
    {
      "start": 1552.56,
      "end": 1556.08,
      "text": "you'll be just collecting all the"
    },
    {
      "start": 1553.92,
      "end": 1558.64,
      "text": "information. So you can think about a uh"
    },
    {
      "start": 1556.08,
      "end": 1560.8,
      "text": "an agent or use case. If you have like"
    },
    {
      "start": 1558.64,
      "end": 1563.28,
      "text": "multiple tasks in your longunning agent"
    },
    {
      "start": 1560.8,
      "end": 1566.0,
      "text": "that are independent from each other,"
    },
    {
      "start": 1563.28,
      "end": 1568.16,
      "text": "you can definitely consider u trimming"
    },
    {
      "start": 1566.0,
      "end": 1569.76,
      "text": "because probably the trimmed or throwed"
    },
    {
      "start": 1568.16,
      "end": 1572.16,
      "text": "away information is not important for"
    },
    {
      "start": 1569.76,
      "end": 1573.76,
      "text": "the agent for the next turns. But if"
    },
    {
      "start": 1572.16,
      "end": 1576.4,
      "text": "you're collecting useful information"
    },
    {
      "start": 1573.76,
      "end": 1578.48,
      "text": "across multiple turns and tasks are"
    },
    {
      "start": 1576.4,
      "end": 1580.64,
      "text": "dependent to each other, then you can"
    },
    {
      "start": 1578.48,
      "end": 1583.64,
      "text": "definitely consider uh summarization"
    },
    {
      "start": 1580.64,
      "end": 1583.64,
      "text": "here."
    },
    {
      "start": 1584.08,
      "end": 1591.44,
      "text": "Nice. Uh so now I'll stop sharing my"
    },
    {
      "start": 1586.64,
      "end": 1594.24,
      "text": "screen and go back to to the demo. I'll"
    },
    {
      "start": 1591.44,
      "end": 1597.6,
      "text": "show you couple examples of these"
    },
    {
      "start": 1594.24,
      "end": 1602.36,
      "text": "techniques that we already covered here."
    },
    {
      "start": 1597.6,
      "end": 1602.36,
      "text": "Let me quickly share my screen."
    },
    {
      "start": 1603.92,
      "end": 1612.0,
      "text": "Nice. So here let's go to configurations"
    },
    {
      "start": 1607.68,
      "end": 1615.04,
      "text": "page uh on the demo. So for agent P I"
    },
    {
      "start": 1612.0,
      "end": 1619.12,
      "text": "want to uh enable trimming and I can"
    },
    {
      "start": 1615.04,
      "end": 1621.44,
      "text": "basically set max turns S3 to trigger uh"
    },
    {
      "start": 1619.12,
      "end": 1626.24,
      "text": "trimming operation. I want to keep"
    },
    {
      "start": 1621.44,
      "end": 1629.12,
      "text": "recent turns uh as S3. So here I can"
    },
    {
      "start": 1626.24,
      "end": 1633.52,
      "text": "start again to test my my agent and"
    },
    {
      "start": 1629.12,
      "end": 1637.36,
      "text": "saying hi. So this time I want to"
    },
    {
      "start": 1633.52,
      "end": 1639.68,
      "text": "understand the refund policy um that I"
    },
    {
      "start": 1637.36,
      "end": 1641.92,
      "text": "want to to check. Maybe I want to refund"
    },
    {
      "start": 1639.68,
      "end": 1644.0,
      "text": "the laptop I just bought. I can say,"
    },
    {
      "start": 1641.92,
      "end": 1647.12,
      "text": "\"Hey, I want this refund policy for my"
    },
    {
      "start": 1644.0,
      "end": 1649.2,
      "text": "MacBook about a month ago. Uh, and I"
    },
    {
      "start": 1647.12,
      "end": 1652.8,
      "text": "want to understand like what's happening"
    },
    {
      "start": 1649.2,
      "end": 1655.68,
      "text": "here um in in terms of refund. So if I'm"
    },
    {
      "start": 1652.8,
      "end": 1658.88,
      "text": "eligible or if I'm not eligible. So the"
    },
    {
      "start": 1655.68,
      "end": 1662.08,
      "text": "model is now making uh a tool call uh"
    },
    {
      "start": 1658.88,
      "end": 1664.56,
      "text": "and calling the get refund tool. Here as"
    },
    {
      "start": 1662.08,
      "end": 1667.92,
      "text": "you see it's returning that specific"
    },
    {
      "start": 1664.56,
      "end": 1671.2,
      "text": "information. I have 30 return window for"
    },
    {
      "start": 1667.92,
      "end": 1674.08,
      "text": "uh for returning that specific laptop."
    },
    {
      "start": 1671.2,
      "end": 1676.24,
      "text": "And I also want to check my my order. So"
    },
    {
      "start": 1674.08,
      "end": 1678.08,
      "text": "I changed my mind and I'm saying, \"Hey,"
    },
    {
      "start": 1676.24,
      "end": 1682.72,
      "text": "can we also check my order? My order"
    },
    {
      "start": 1678.08,
      "end": 1684.8,
      "text": "number is 1 2 3 4 5.\" Uh and I want to"
    },
    {
      "start": 1682.72,
      "end": 1686.32,
      "text": "see like if it's if it's on the way, if"
    },
    {
      "start": 1684.8,
      "end": 1689.44,
      "text": "it's coming. So you see that the model"
    },
    {
      "start": 1686.32,
      "end": 1691.28,
      "text": "is doing another tool call as as get"
    },
    {
      "start": 1689.44,
      "end": 1693.04,
      "text": "order."
    },
    {
      "start": 1691.28,
      "end": 1694.8,
      "text": "And now I want to switch gears. I can"
    },
    {
      "start": 1693.04,
      "end": 1697.52,
      "text": "say, \"Hey, thanks. I'm having an issue"
    },
    {
      "start": 1694.8,
      "end": 1700.64,
      "text": "with the internet connection. So until"
    },
    {
      "start": 1697.52,
      "end": 1703.84,
      "text": "this turn, you see that I have lots of"
    },
    {
      "start": 1700.64,
      "end": 1707.36,
      "text": "tool tokens here in the context in"
    },
    {
      "start": 1703.84,
      "end": 1710.72,
      "text": "context life cycle. So it's getting uh"
    },
    {
      "start": 1707.36,
      "end": 1713.28,
      "text": "accumulating over turns and in that"
    },
    {
      "start": 1710.72,
      "end": 1716.72,
      "text": "specific turn now it's telling me that"
    },
    {
      "start": 1713.28,
      "end": 1720.48,
      "text": "hey let's sort it out. It's asking me a"
    },
    {
      "start": 1716.72,
      "end": 1722.72,
      "text": "couple questions um about my my device"
    },
    {
      "start": 1720.48,
      "end": 1725.6,
      "text": "and I can say hey I tried to to load an"
    },
    {
      "start": 1722.72,
      "end": 1729.84,
      "text": "internet page and still see 40 404"
    },
    {
      "start": 1725.6,
      "end": 1732.0,
      "text": "error. Um I basically share a couple uh"
    },
    {
      "start": 1729.84,
      "end": 1734.96,
      "text": "important information about the"
    },
    {
      "start": 1732.0,
      "end": 1737.28,
      "text": "situation and you see still see that the"
    },
    {
      "start": 1734.96,
      "end": 1741.36,
      "text": "across the turns it's accumulating lots"
    },
    {
      "start": 1737.28,
      "end": 1743.6,
      "text": "of lots of tokens and even agent output"
    },
    {
      "start": 1741.36,
      "end": 1746.16,
      "text": "is is increasing."
    },
    {
      "start": 1743.6,
      "end": 1750.24,
      "text": "Okay. So let's say it's still happening"
    },
    {
      "start": 1746.16,
      "end": 1752.32,
      "text": "on on Safari. Um and then"
    },
    {
      "start": 1750.24,
      "end": 1754.32,
      "text": "this is the last message probably uh"
    },
    {
      "start": 1752.32,
      "end": 1756.96,
      "text": "that I that I want to share about the"
    },
    {
      "start": 1754.32,
      "end": 1759.6,
      "text": "current situation and I'm waiting to to"
    },
    {
      "start": 1756.96,
      "end": 1762.4,
      "text": "have more guidance and instructions uh"
    },
    {
      "start": 1759.6,
      "end": 1765.52,
      "text": "here. And here you see that at the end"
    },
    {
      "start": 1762.4,
      "end": 1769.04,
      "text": "of turn six the context is trimmed. Uh"
    },
    {
      "start": 1765.52,
      "end": 1771.84,
      "text": "if I go back to here to visualize what's"
    },
    {
      "start": 1769.04,
      "end": 1773.6,
      "text": "happening. So when I hit the the turn"
    },
    {
      "start": 1771.84,
      "end": 1775.76,
      "text": "six, you see that it trimmed the"
    },
    {
      "start": 1773.6,
      "end": 1778.08,
      "text": "context. So it basically removed all"
    },
    {
      "start": 1775.76,
      "end": 1782.56,
      "text": "these tool tool outputs and tool tokens."
    },
    {
      "start": 1778.08,
      "end": 1785.12,
      "text": "So now I have a fresh context here. Um"
    },
    {
      "start": 1782.56,
      "end": 1789.28,
      "text": "and then now I can continue talking"
    },
    {
      "start": 1785.12,
      "end": 1792.56,
      "text": "about the same specific issue or I can"
    },
    {
      "start": 1789.28,
      "end": 1794.96,
      "text": "continue to to talk about like different"
    },
    {
      "start": 1792.56,
      "end": 1798.4,
      "text": "different information."
    },
    {
      "start": 1794.96,
      "end": 1801.76,
      "text": "Nice. So let's go back and then here I"
    },
    {
      "start": 1798.4,
      "end": 1804.32,
      "text": "also want to show you how"
    },
    {
      "start": 1801.76,
      "end": 1806.16,
      "text": "summarization works. So also the"
    },
    {
      "start": 1804.32,
      "end": 1809.2,
      "text": "compaction is also works in a similar"
    },
    {
      "start": 1806.16,
      "end": 1812.08,
      "text": "way as a trimming. So here I can set uh"
    },
    {
      "start": 1809.2,
      "end": 1815.12,
      "text": "like compaction trigger as for and keep"
    },
    {
      "start": 1812.08,
      "end": 1816.88,
      "text": "recent recent turns too. So you'll see"
    },
    {
      "start": 1815.12,
      "end": 1819.44,
      "text": "that at the end of turn two, it'll be"
    },
    {
      "start": 1816.88,
      "end": 1822.88,
      "text": "compacting and removing all these tool"
    },
    {
      "start": 1819.44,
      "end": 1826.0,
      "text": "outputs and I'll have a a fresh context"
    },
    {
      "start": 1822.88,
      "end": 1828.72,
      "text": "similar to to the trimming approach."
    },
    {
      "start": 1826.0,
      "end": 1832.24,
      "text": "But now I want to be a little bit more"
    },
    {
      "start": 1828.72,
      "end": 1835.28,
      "text": "advanced here. So here I want to enable"
    },
    {
      "start": 1832.24,
      "end": 1837.2,
      "text": "summarization. Um"
    },
    {
      "start": 1835.28,
      "end": 1839.68,
      "text": "I want to set the the summarization"
    },
    {
      "start": 1837.2,
      "end": 1843.36,
      "text": "trigger as five and I want to keep the"
    },
    {
      "start": 1839.68,
      "end": 1847.68,
      "text": "the recent three turns. So here I I"
    },
    {
      "start": 1843.36,
      "end": 1849.36,
      "text": "clicked save and now I want to just see"
    },
    {
      "start": 1847.68,
      "end": 1852.24,
      "text": "how it's summarizing all these"
    },
    {
      "start": 1849.36,
      "end": 1854.32,
      "text": "information. So here I'm sending hey I"
    },
    {
      "start": 1852.24,
      "end": 1857.04,
      "text": "I'm having internet connection again. So"
    },
    {
      "start": 1854.32,
      "end": 1859.12,
      "text": "this time I decided to share more and"
    },
    {
      "start": 1857.04,
      "end": 1861.04,
      "text": "more information about my my situation."
    },
    {
      "start": 1859.12,
      "end": 1864.64,
      "text": "So I can say where I bought this"
    },
    {
      "start": 1861.04,
      "end": 1867.28,
      "text": "computer um what is is the model. So I"
    },
    {
      "start": 1864.64,
      "end": 1870.64,
      "text": "can say, \"Hey, I have a 2014 MacBook Pro"
    },
    {
      "start": 1867.28,
      "end": 1873.44,
      "text": "14inch and I live in the US, but I"
    },
    {
      "start": 1870.64,
      "end": 1875.2,
      "text": "bought it from Amsterdam. I received it"
    },
    {
      "start": 1873.44,
      "end": 1877.6,
      "text": "from from battery change service and"
    },
    {
      "start": 1875.2,
      "end": 1879.52,
      "text": "just updated the OS version last week"
    },
    {
      "start": 1877.6,
      "end": 1882.64,
      "text": "and they asked me to update the OS"
    },
    {
      "start": 1879.52,
      "end": 1884.8,
      "text": "version to Mac me OS Seoia."
    },
    {
      "start": 1882.64,
      "end": 1886.96,
      "text": "So as you see, I'm sharing like many"
    },
    {
      "start": 1884.8,
      "end": 1889.52,
      "text": "information uh and these informations"
    },
    {
      "start": 1886.96,
      "end": 1892.72,
      "text": "are really available for an IT trouble"
    },
    {
      "start": 1889.52,
      "end": 1895.12,
      "text": "troubleshooting agent, right? Uh and"
    },
    {
      "start": 1892.72,
      "end": 1898.24,
      "text": "here I can go back and say okay these"
    },
    {
      "start": 1895.12,
      "end": 1900.56,
      "text": "are nice clarify the problem"
    },
    {
      "start": 1898.24,
      "end": 1904.0,
      "text": "uh like what I need from you and I can"
    },
    {
      "start": 1900.56,
      "end": 1905.92,
      "text": "say hey I already tried hard reset after"
    },
    {
      "start": 1904.0,
      "end": 1908.24,
      "text": "checking the FAQ docs but it didn't"
    },
    {
      "start": 1905.92,
      "end": 1910.08,
      "text": "work. So this is still in a form of"
    },
    {
      "start": 1908.24,
      "end": 1913.84,
      "text": "memory because I'm sharing like which"
    },
    {
      "start": 1910.08,
      "end": 1918.4,
      "text": "steps I tried which worked and and which"
    },
    {
      "start": 1913.84,
      "end": 1920.08,
      "text": "didn't work. I can go back um and"
    },
    {
      "start": 1918.4,
      "end": 1922.24,
      "text": "continue talking with the agent. So now"
    },
    {
      "start": 1920.08,
      "end": 1924.64,
      "text": "it's reasoning itself and providing me"
    },
    {
      "start": 1922.24,
      "end": 1927.76,
      "text": "like more detailed guidance uh and"
    },
    {
      "start": 1924.64,
      "end": 1931.76,
      "text": "instructions for specific to to a"
    },
    {
      "start": 1927.76,
      "end": 1934.24,
      "text": "MacBook. So I I go back I went back to"
    },
    {
      "start": 1931.76,
      "end": 1938.88,
      "text": "my computer and I saw that the Wi-Fi"
    },
    {
      "start": 1934.24,
      "end": 1941.76,
      "text": "icon is is not active. Um and then I'm"
    },
    {
      "start": 1938.88,
      "end": 1944.72,
      "text": "thinking maybe it's related to to Wi-Fi"
    },
    {
      "start": 1941.76,
      "end": 1947.36,
      "text": "or maybe it's related to a specific um"
    },
    {
      "start": 1944.72,
      "end": 1949.92,
      "text": "software issue. So, as you see across"
    },
    {
      "start": 1947.36,
      "end": 1951.84,
      "text": "the turns, it's it's getting more"
    },
    {
      "start": 1949.92,
      "end": 1954.48,
      "text": "complex. The the the agent needs to"
    },
    {
      "start": 1951.84,
      "end": 1956.88,
      "text": "reason and the agent also needs to keep"
    },
    {
      "start": 1954.48,
      "end": 1959.76,
      "text": "track of what's in in its context and"
    },
    {
      "start": 1956.88,
      "end": 1963.36,
      "text": "make sure that it's not uh there's no"
    },
    {
      "start": 1959.76,
      "end": 1965.52,
      "text": "burst, there's no conflict. Um there's"
    },
    {
      "start": 1963.36,
      "end": 1968.88,
      "text": "no poisoning and other type of failure"
    },
    {
      "start": 1965.52,
      "end": 1970.96,
      "text": "modes. It's telling me uh some specific"
    },
    {
      "start": 1968.88,
      "end": 1973.28,
      "text": "steps and I can say, \"Hey, I tried it"
    },
    {
      "start": 1970.96,
      "end": 1977.92,
      "text": "already and I'm wondering if it's a"
    },
    {
      "start": 1973.28,
      "end": 1980.24,
      "text": "specific software issue, right?\" Um and"
    },
    {
      "start": 1977.92,
      "end": 1982.8,
      "text": "then here I'm waiting for the response"
    },
    {
      "start": 1980.24,
      "end": 1985.12,
      "text": "from from the agent. So again, I shared"
    },
    {
      "start": 1982.8,
      "end": 1987.36,
      "text": "lots of information here. Uh lots of"
    },
    {
      "start": 1985.12,
      "end": 1990.96,
      "text": "available information. So now the agent"
    },
    {
      "start": 1987.36,
      "end": 1994.64,
      "text": "knows my device, where I bought this"
    },
    {
      "start": 1990.96,
      "end": 1998.56,
      "text": "device, which steps I tried. Um and"
    },
    {
      "start": 1994.64,
      "end": 2002.32,
      "text": "basically what I what type of um steps I"
    },
    {
      "start": 1998.56,
      "end": 2005.44,
      "text": "performed before uh doing that."
    },
    {
      "start": 2002.32,
      "end": 2007.36,
      "text": "Cool. Uh so now you see that it's"
    },
    {
      "start": 2005.44,
      "end": 2009.44,
      "text": "responded to me like a very well"
    },
    {
      "start": 2007.36,
      "end": 2012.48,
      "text": "structured instructions given what you"
    },
    {
      "start": 2009.44,
      "end": 2014.88,
      "text": "described. Wi-Fi icon is not active blah"
    },
    {
      "start": 2012.48,
      "end": 2017.92,
      "text": "blah. And then here I see that the"
    },
    {
      "start": 2014.88,
      "end": 2021.52,
      "text": "context is summarized and I notice that"
    },
    {
      "start": 2017.92,
      "end": 2024.16,
      "text": "there is an orange uh component we count"
    },
    {
      "start": 2021.52,
      "end": 2029.44,
      "text": "as memory item and the memory item is"
    },
    {
      "start": 2024.16,
      "end": 2032.56,
      "text": "basically um the summary uh that we had."
    },
    {
      "start": 2029.44,
      "end": 2034.8,
      "text": "So here between turn four and turn five"
    },
    {
      "start": 2032.56,
      "end": 2038.24,
      "text": "you see that I'm I'm condensing some"
    },
    {
      "start": 2034.8,
      "end": 2041.92,
      "text": "part of the context and I'm injecting it"
    },
    {
      "start": 2038.24,
      "end": 2044.32,
      "text": "back as a user message uh as as a memory"
    },
    {
      "start": 2041.92,
      "end": 2047.84,
      "text": "component. So again here memory is"
    },
    {
      "start": 2044.32,
      "end": 2050.4,
      "text": "basically um the the summarized context"
    },
    {
      "start": 2047.84,
      "end": 2053.68,
      "text": "from the previous terms."
    },
    {
      "start": 2050.4,
      "end": 2057.68,
      "text": "So now I want to go back to the code and"
    },
    {
      "start": 2053.68,
      "end": 2059.52,
      "text": "show you the the summary prompt"
    },
    {
      "start": 2057.68,
      "end": 2063.04,
      "text": "uh and go over like some important"
    },
    {
      "start": 2059.52,
      "end": 2065.44,
      "text": "topics about this specific prompt. So as"
    },
    {
      "start": 2063.04,
      "end": 2066.96,
      "text": "you see uh here's my summary prompt. I'm"
    },
    {
      "start": 2065.44,
      "end": 2070.0,
      "text": "saying hey you are a senior customer"
    },
    {
      "start": 2066.96,
      "end": 2074.0,
      "text": "support assistant for tech devices setup"
    },
    {
      "start": 2070.0,
      "end": 2077.52,
      "text": "and software issues. Um, and then before"
    },
    {
      "start": 2074.0,
      "end": 2079.52,
      "text": "you write, I'm saying, uh, hey, be"
    },
    {
      "start": 2077.52,
      "end": 2082.16,
      "text": "careful with contradictions."
    },
    {
      "start": 2079.52,
      "end": 2084.4,
      "text": "Uh, make sure you are having a temporal"
    },
    {
      "start": 2082.16,
      "end": 2085.92,
      "text": "ordering and make sure you're having a"
    },
    {
      "start": 2084.4,
      "end": 2088.32,
      "text": "hallucination control. So, I think these"
    },
    {
      "start": 2085.92,
      "end": 2090.0,
      "text": "are very important things to consider"
    },
    {
      "start": 2088.32,
      "end": 2093.04,
      "text": "when writing a well-crafted"
    },
    {
      "start": 2090.0,
      "end": 2096.16,
      "text": "summarization prompt. And then I'm tying"
    },
    {
      "start": 2093.04,
      "end": 2098.16,
      "text": "this summary to my specific use case."
    },
    {
      "start": 2096.16,
      "end": 2100.96,
      "text": "So, I'm saying, hey, in your summary,"
    },
    {
      "start": 2098.16,
      "end": 2102.88,
      "text": "write a structured factual summary. And"
    },
    {
      "start": 2100.96,
      "end": 2105.12,
      "text": "then just think about product"
    },
    {
      "start": 2102.88,
      "end": 2107.76,
      "text": "environment reported issues, what worked"
    },
    {
      "start": 2105.12,
      "end": 2110.0,
      "text": "and what didn't work. Uh which steps you"
    },
    {
      "start": 2107.76,
      "end": 2113.12,
      "text": "tried, include identifiers, which is"
    },
    {
      "start": 2110.0,
      "end": 2115.36,
      "text": "important, key timelines,"
    },
    {
      "start": 2113.12,
      "end": 2117.12,
      "text": "uh timeline milestones, tool performance"
    },
    {
      "start": 2115.36,
      "end": 2119.68,
      "text": "insight, current status, and next"
    },
    {
      "start": 2117.12,
      "end": 2121.44,
      "text": "recommended steps."
    },
    {
      "start": 2119.68,
      "end": 2125.12,
      "text": "So this is a really nice example of how"
    },
    {
      "start": 2121.44,
      "end": 2127.28,
      "text": "to craft a summarization prompt. Um, and"
    },
    {
      "start": 2125.12,
      "end": 2128.96,
      "text": "then here if I go back to the context"
    },
    {
      "start": 2127.28,
      "end": 2130.56,
      "text": "summary,"
    },
    {
      "start": 2128.96,
      "end": 2132.8,
      "text": "I'm seeing like lots of useful"
    },
    {
      "start": 2130.56,
      "end": 2135.44,
      "text": "information. So now I'm seeing, hey, the"
    },
    {
      "start": 2132.8,
      "end": 2137.76,
      "text": "device is is MacBook Pro. The the"
    },
    {
      "start": 2135.44,
      "end": 2139.68,
      "text": "operation system mecha it's bought from"
    },
    {
      "start": 2137.76,
      "end": 2142.4,
      "text": "it's purchased in Amsterdam, but"
    },
    {
      "start": 2139.68,
      "end": 2148.0,
      "text": "location is the USA. You see like which"
    },
    {
      "start": 2142.4,
      "end": 2150.96,
      "text": "steps I tried even uh I tried um uh the"
    },
    {
      "start": 2148.0,
      "end": 2153.76,
      "text": "different uh steps to connect to to the"
    },
    {
      "start": 2150.96,
      "end": 2156.16,
      "text": "network. you see milestones, I did a"
    },
    {
      "start": 2153.76,
      "end": 2157.76,
      "text": "better replacement which is an important"
    },
    {
      "start": 2156.16,
      "end": 2159.68,
      "text": "information"
    },
    {
      "start": 2157.76,
      "end": 2161.84,
      "text": "uh which steps suggested connect"
    },
    {
      "start": 2159.68,
      "end": 2164.48,
      "text": "connection issue and lots of useful"
    },
    {
      "start": 2161.84,
      "end": 2166.88,
      "text": "details. So I think this is really dense"
    },
    {
      "start": 2164.48,
      "end": 2170.24,
      "text": "um information that you might have about"
    },
    {
      "start": 2166.88,
      "end": 2174.24,
      "text": "your your context."
    },
    {
      "start": 2170.24,
      "end": 2177.44,
      "text": "Cool. Uh and finally I want to show you"
    },
    {
      "start": 2174.24,
      "end": 2179.6,
      "text": "a form of a long-term memory. Um so here"
    },
    {
      "start": 2177.44,
      "end": 2181.92,
      "text": "let's say I'll talk with an AI agent."
    },
    {
      "start": 2179.6,
      "end": 2183.36,
      "text": "Now I created my my my summary got"
    },
    {
      "start": 2181.92,
      "end": 2186.8,
      "text": "created. There are lots of information"
    },
    {
      "start": 2183.36,
      "end": 2190.16,
      "text": "that the agent know about me. So now I'm"
    },
    {
      "start": 2186.8,
      "end": 2193.68,
      "text": "resetting my my agent and going back and"
    },
    {
      "start": 2190.16,
      "end": 2195.84,
      "text": "enable this cross session feature. So"
    },
    {
      "start": 2193.68,
      "end": 2198.4,
      "text": "when I enable this this generated"
    },
    {
      "start": 2195.84,
      "end": 2202.24,
      "text": "summary from previous example will be"
    },
    {
      "start": 2198.4,
      "end": 2207.68,
      "text": "injected into the system prompt uh when"
    },
    {
      "start": 2202.24,
      "end": 2209.36,
      "text": "I try to trigger a new new session."
    },
    {
      "start": 2207.68,
      "end": 2212.32,
      "text": "Now"
    },
    {
      "start": 2209.36,
      "end": 2215.52,
      "text": "I enable that specific feature injection"
    },
    {
      "start": 2212.32,
      "end": 2218.88,
      "text": "and I can say hi and I'll I'll send this"
    },
    {
      "start": 2215.52,
      "end": 2221.68,
      "text": "the both of the same um like similar"
    },
    {
      "start": 2218.88,
      "end": 2223.6,
      "text": "agents. So the one on the right it says"
    },
    {
      "start": 2221.68,
      "end": 2225.28,
      "text": "hey good to see you again. Are you still"
    },
    {
      "start": 2223.6,
      "end": 2227.28,
      "text": "having issues with your MacBook's"
    },
    {
      "start": 2225.28,
      "end": 2229.84,
      "text": "internet connection after the Mac OS"
    },
    {
      "start": 2227.28,
      "end": 2231.6,
      "text": "Seoia update. So as you see that the"
    },
    {
      "start": 2229.84,
      "end": 2234.32,
      "text": "response on the right it's it's super"
    },
    {
      "start": 2231.6,
      "end": 2236.24,
      "text": "personalized because of this memory"
    },
    {
      "start": 2234.32,
      "end": 2238.56,
      "text": "component that I injected into the"
    },
    {
      "start": 2236.24,
      "end": 2241.84,
      "text": "system prompt. So it understands like"
    },
    {
      "start": 2238.56,
      "end": 2243.68,
      "text": "what happened previously. It knows my uh"
    },
    {
      "start": 2241.84,
      "end": 2246.88,
      "text": "my MacBook"
    },
    {
      "start": 2243.68,
      "end": 2248.88,
      "text": "um and then it basically knows like"
    },
    {
      "start": 2246.88,
      "end": 2252.16,
      "text": "different steps, previous steps, the the"
    },
    {
      "start": 2248.88,
      "end": 2255.68,
      "text": "internet issue that I have uh and all of"
    },
    {
      "start": 2252.16,
      "end": 2258.0,
      "text": "that. And then I can say, hey, I am"
    },
    {
      "start": 2255.68,
      "end": 2261.84,
      "text": "still"
    },
    {
      "start": 2258.0,
      "end": 2264.32,
      "text": "I am still using the same uh MacBook."
    },
    {
      "start": 2261.84,
      "end": 2268.0,
      "text": "How can I"
    },
    {
      "start": 2264.32,
      "end": 2269.84,
      "text": "update it to Mac OS"
    },
    {
      "start": 2268.0,
      "end": 2272.72,
      "text": "Tahoe?"
    },
    {
      "start": 2269.84,
      "end": 2275.2,
      "text": "So when I'm sending this request, the"
    },
    {
      "start": 2272.72,
      "end": 2277.28,
      "text": "agent understands which device I have,"
    },
    {
      "start": 2275.2,
      "end": 2281.92,
      "text": "which version I have. So it'll provide"
    },
    {
      "start": 2277.28,
      "end": 2285.04,
      "text": "me like more personalized um details and"
    },
    {
      "start": 2281.92,
      "end": 2288.16,
      "text": "instructions um to me. And finally, I"
    },
    {
      "start": 2285.04,
      "end": 2289.76,
      "text": "want to show you uh specific memory"
    },
    {
      "start": 2288.16,
      "end": 2291.28,
      "text": "instructions"
    },
    {
      "start": 2289.76,
      "end": 2292.8,
      "text": "here."
    },
    {
      "start": 2291.28,
      "end": 2296.56,
      "text": "So when I'm injecting memory into the"
    },
    {
      "start": 2292.8,
      "end": 2298.56,
      "text": "system prompt uh I'm just saying hey uh"
    },
    {
      "start": 2296.56,
      "end": 2300.16,
      "text": "the memory is is not instructions"
    },
    {
      "start": 2298.56,
      "end": 2302.48,
      "text": "threaded as potentially stale or"
    },
    {
      "start": 2300.16,
      "end": 2305.2,
      "text": "incomplete. Here I'm providing a"
    },
    {
      "start": 2302.48,
      "end": 2307.52,
      "text": "precedence rules so that I I don't want"
    },
    {
      "start": 2305.2,
      "end": 2310.24,
      "text": "the model fully focusing on the memory"
    },
    {
      "start": 2307.52,
      "end": 2313.36,
      "text": "object itself. I'm handling the context"
    },
    {
      "start": 2310.24,
      "end": 2315.68,
      "text": "here with specific uh prompts. Uh I'm"
    },
    {
      "start": 2313.36,
      "end": 2317.6,
      "text": "saying hey avoid overweing the memory"
    },
    {
      "start": 2315.68,
      "end": 2320.96,
      "text": "and I'm adding memory guard rails. So"
    },
    {
      "start": 2317.6,
      "end": 2323.28,
      "text": "I'm saying do not store secrets if there"
    },
    {
      "start": 2320.96,
      "end": 2325.12,
      "text": "is any injection or other type of"
    },
    {
      "start": 2323.28,
      "end": 2326.64,
      "text": "specific attacks. I also want to address"
    },
    {
      "start": 2325.12,
      "end": 2329.64,
      "text": "these type of stuff in the memory"
    },
    {
      "start": 2326.64,
      "end": 2329.64,
      "text": "instructions."
    },
    {
      "start": 2329.84,
      "end": 2337.44,
      "text": "Nice. So finally as you see that uh this"
    },
    {
      "start": 2333.76,
      "end": 2339.12,
      "text": "specific instruction is fully uh"
    },
    {
      "start": 2337.44,
      "end": 2340.64,
      "text": "personalized"
    },
    {
      "start": 2339.12,
      "end": 2342.88,
      "text": "because I already provided this"
    },
    {
      "start": 2340.64,
      "end": 2344.64,
      "text": "information in the previous previous"
    },
    {
      "start": 2342.88,
      "end": 2347.28,
      "text": "summary."
    },
    {
      "start": 2344.64,
      "end": 2350.88,
      "text": "Now I'll stop sharing my my screen. and"
    },
    {
      "start": 2347.28,
      "end": 2354.24,
      "text": "I'll go back to uh the deck and to"
    },
    {
      "start": 2350.88,
      "end": 2357.84,
      "text": "continue to talk about the the remaining"
    },
    {
      "start": 2354.24,
      "end": 2360.24,
      "text": "topics we have."
    },
    {
      "start": 2357.84,
      "end": 2362.8,
      "text": "Let's go."
    },
    {
      "start": 2360.24,
      "end": 2365.92,
      "text": "Cool. I also want to quickly talk about"
    },
    {
      "start": 2362.8,
      "end": 2368.96,
      "text": "like couple other techniques. Um the"
    },
    {
      "start": 2365.92,
      "end": 2371.44,
      "text": "isolator route bucket is consist of tool"
    },
    {
      "start": 2368.96,
      "end": 2374.0,
      "text": "offloading to sub aents. So it means we"
    },
    {
      "start": 2371.44,
      "end": 2376.16,
      "text": "are uploading specific uh context and"
    },
    {
      "start": 2374.0,
      "end": 2380.56,
      "text": "tools to specific sub aents. So this is"
    },
    {
      "start": 2376.16,
      "end": 2384.32,
      "text": "a nice form of um uh an isolate and"
    },
    {
      "start": 2380.56,
      "end": 2386.48,
      "text": "route technique. And then um here you"
    },
    {
      "start": 2384.32,
      "end": 2388.24,
      "text": "see that there will be like a new uh and"
    },
    {
      "start": 2386.48,
      "end": 2390.48,
      "text": "fresh context. You'll be minimizing"
    },
    {
      "start": 2388.24,
      "end": 2393.84,
      "text": "context conflict and poisoning just by"
    },
    {
      "start": 2390.48,
      "end": 2395.44,
      "text": "routing the specific sub agents."
    },
    {
      "start": 2393.84,
      "end": 2398.64,
      "text": "In the final bucket I want to a little"
    },
    {
      "start": 2395.44,
      "end": 2400.56,
      "text": "bit talk about the shape of a memory. So"
    },
    {
      "start": 2398.64,
      "end": 2403.28,
      "text": "when you think about a memory it can be"
    },
    {
      "start": 2400.56,
      "end": 2404.88,
      "text": "many different things. Um so the"
    },
    {
      "start": 2403.28,
      "end": 2408.16,
      "text": "suggestion is basically is starting"
    },
    {
      "start": 2404.88,
      "end": 2410.16,
      "text": "simple and evolve as needed. So you can"
    },
    {
      "start": 2408.16,
      "end": 2412.96,
      "text": "use consistent structured formats. You"
    },
    {
      "start": 2410.16,
      "end": 2414.56,
      "text": "can prioritize what what a human agent"
    },
    {
      "start": 2412.96,
      "end": 2416.96,
      "text": "uh what what a human agent would"
    },
    {
      "start": 2414.56,
      "end": 2419.44,
      "text": "naturally remember. And finally you see"
    },
    {
      "start": 2416.96,
      "end": 2421.76,
      "text": "the most complex uh form which is"
    },
    {
      "start": 2419.44,
      "end": 2424.08,
      "text": "basically a paragraph of a memory. So"
    },
    {
      "start": 2421.76,
      "end": 2427.2,
      "text": "you can start with a simple one and you"
    },
    {
      "start": 2424.08,
      "end": 2429.68,
      "text": "can evolve uh as needed."
    },
    {
      "start": 2427.2,
      "end": 2431.76,
      "text": "And for extraction uh you can use a"
    },
    {
      "start": 2429.68,
      "end": 2434.48,
      "text": "memory tool to extract memories in the"
    },
    {
      "start": 2431.76,
      "end": 2436.96,
      "text": "live terms. So you can store memory in a"
    },
    {
      "start": 2434.48,
      "end": 2440.16,
      "text": "in a JSON as a as a one or two sentence"
    },
    {
      "start": 2436.96,
      "end": 2442.4,
      "text": "note. Um you can use type save"
    },
    {
      "start": 2440.16,
      "end": 2444.8,
      "text": "functions. Uh you can use markdown"
    },
    {
      "start": 2442.4,
      "end": 2446.48,
      "text": "format and other type of techniques when"
    },
    {
      "start": 2444.8,
      "end": 2448.72,
      "text": "you're writing this specific tool for"
    },
    {
      "start": 2446.48,
      "end": 2450.96,
      "text": "saving the memory."
    },
    {
      "start": 2448.72,
      "end": 2453.76,
      "text": "And then another approach is basically"
    },
    {
      "start": 2450.96,
      "end": 2455.84,
      "text": "state management. uh in the last bucket."
    },
    {
      "start": 2453.76,
      "end": 2458.08,
      "text": "So it's basically defining a state"
    },
    {
      "start": 2455.84,
      "end": 2461.04,
      "text": "object with goal uh and different"
    },
    {
      "start": 2458.08,
      "end": 2464.0,
      "text": "information and you can even inject uh"
    },
    {
      "start": 2461.04,
      "end": 2466.56,
      "text": "the state back into the system prompt uh"
    },
    {
      "start": 2464.0,
      "end": 2469.04,
      "text": "across multiple turns in a frequency or"
    },
    {
      "start": 2466.56,
      "end": 2470.72,
      "text": "you can inject it back into into the new"
    },
    {
      "start": 2469.04,
      "end": 2474.0,
      "text": "session."
    },
    {
      "start": 2470.72,
      "end": 2476.48,
      "text": "And finally retrieval uh we can perform"
    },
    {
      "start": 2474.0,
      "end": 2479.12,
      "text": "a memory retrieval with a tool. Uh so"
    },
    {
      "start": 2476.48,
      "end": 2480.96,
      "text": "it's similar to a rag approach. So you"
    },
    {
      "start": 2479.12,
      "end": 2483.6,
      "text": "can basically store these these memories"
    },
    {
      "start": 2480.96,
      "end": 2486.72,
      "text": "into a long-term store and a vector DB"
    },
    {
      "start": 2483.6,
      "end": 2490.0,
      "text": "and during the live turns you can um"
    },
    {
      "start": 2486.72,
      "end": 2495.2,
      "text": "basically like make a search filter rank"
    },
    {
      "start": 2490.0,
      "end": 2499.36,
      "text": "and inject it back into into the agents."
    },
    {
      "start": 2495.2,
      "end": 2501.52,
      "text": "Nice. So finally I want to wrap up. Um"
    },
    {
      "start": 2499.36,
      "end": 2503.52,
      "text": "so I want to reiterate best practices in"
    },
    {
      "start": 2501.52,
      "end": 2505.36,
      "text": "in in agent memory design. So first one"
    },
    {
      "start": 2503.52,
      "end": 2506.88,
      "text": "is basically understanding your typical"
    },
    {
      "start": 2505.36,
      "end": 2508.64,
      "text": "context."
    },
    {
      "start": 2506.88,
      "end": 2511.28,
      "text": "uh and you should define what is"
    },
    {
      "start": 2508.64,
      "end": 2514.64,
      "text": "meaningful for you and for your agent."
    },
    {
      "start": 2511.28,
      "end": 2516.88,
      "text": "The second point is deciding when and"
    },
    {
      "start": 2514.64,
      "end": 2519.44,
      "text": "how to remember and forget. So you can"
    },
    {
      "start": 2516.88,
      "end": 2522.16,
      "text": "promote stable reusable facts to memory"
    },
    {
      "start": 2519.44,
      "end": 2525.04,
      "text": "and activity forget temporarily stale or"
    },
    {
      "start": 2522.16,
      "end": 2527.76,
      "text": "lo confidence information and you'll see"
    },
    {
      "start": 2525.04,
      "end": 2530.16,
      "text": "that your memories will be evolving uh"
    },
    {
      "start": 2527.76,
      "end": 2533.36,
      "text": "over time uh and you can continuously"
    },
    {
      "start": 2530.16,
      "end": 2535.84,
      "text": "clean merge and consolidate memories uh"
    },
    {
      "start": 2533.36,
      "end": 2539.2,
      "text": "and you can optimize these steps uh in"
    },
    {
      "start": 2535.84,
      "end": 2541.92,
      "text": "iterations and finally evals is is also"
    },
    {
      "start": 2539.2,
      "end": 2544.64,
      "text": "super important. So you can run your own"
    },
    {
      "start": 2541.92,
      "end": 2547.44,
      "text": "evals to see if there is any uh uh"
    },
    {
      "start": 2544.64,
      "end": 2549.2,
      "text": "improvement with memory on and off. You"
    },
    {
      "start": 2547.44,
      "end": 2551.52,
      "text": "can even build your memory specific"
    },
    {
      "start": 2549.2,
      "end": 2554.48,
      "text": "evals for long running task and and long"
    },
    {
      "start": 2551.52,
      "end": 2556.24,
      "text": "context."
    },
    {
      "start": 2554.48,
      "end": 2558.16,
      "text": ">> Awesome. With that, let's move on to"
    },
    {
      "start": 2556.24,
      "end": 2560.32,
      "text": "some Q&A. We've had a ton of great"
    },
    {
      "start": 2558.16,
      "end": 2562.48,
      "text": "questions come in. So why don't we re"
    },
    {
      "start": 2560.32,
      "end": 2566.0,
      "text": "refresh the presentation and we'll pull"
    },
    {
      "start": 2562.48,
      "end": 2569.6,
      "text": "up the next slide and get into a few."
    },
    {
      "start": 2566.0,
      "end": 2571.2,
      "text": ">> Nice. Okay. So let me go back to the Q&A"
    },
    {
      "start": 2569.6,
      "end": 2574.08,
      "text": "session"
    },
    {
      "start": 2571.2,
      "end": 2576.32,
      "text": "and jump into"
    },
    {
      "start": 2574.08,
      "end": 2579.8,
      "text": "the questions we have. So let me quickly"
    },
    {
      "start": 2576.32,
      "end": 2579.8,
      "text": "share it again."
    },
    {
      "start": 2580.48,
      "end": 2584.8,
      "text": "Nice."
    },
    {
      "start": 2582.56,
      "end": 2586.64,
      "text": "Okay."
    },
    {
      "start": 2584.8,
      "end": 2589.64,
      "text": "Yeah. Let's start with the the first"
    },
    {
      "start": 2586.64,
      "end": 2589.64,
      "text": "questions."
    },
    {
      "start": 2592.08,
      "end": 2596.8,
      "text": "Yeah. So there are li any libraries or"
    },
    {
      "start": 2594.16,
      "end": 2599.04,
      "text": "packages uh to recommend for context"
    },
    {
      "start": 2596.8,
      "end": 2602.16,
      "text": "engineering. So this demo is built by"
    },
    {
      "start": 2599.04,
      "end": 2604.16,
      "text": "using uh open agents SDK package and"
    },
    {
      "start": 2602.16,
      "end": 2607.52,
      "text": "library. It gives you a really good"
    },
    {
      "start": 2604.16,
      "end": 2610.32,
      "text": "flexibility um to implement your own"
    },
    {
      "start": 2607.52,
      "end": 2612.16,
      "text": "sessions. Uh and in these sessions you"
    },
    {
      "start": 2610.32,
      "end": 2614.56,
      "text": "can easily implement like trimming,"
    },
    {
      "start": 2612.16,
      "end": 2618.0,
      "text": "compaction, summarization and all of"
    },
    {
      "start": 2614.56,
      "end": 2622.0,
      "text": "that type of uh techniques easily here."
    },
    {
      "start": 2618.0,
      "end": 2624.32,
      "text": "Um so I see many different libraries uh"
    },
    {
      "start": 2622.0,
      "end": 2627.28,
      "text": "that are evolving really fast to"
    },
    {
      "start": 2624.32,
      "end": 2629.12,
      "text": "basically um make your life easier for"
    },
    {
      "start": 2627.28,
      "end": 2632.72,
      "text": "for context engineering. So as you see"
    },
    {
      "start": 2629.12,
      "end": 2634.32,
      "text": "we have too many um techniques and each"
    },
    {
      "start": 2632.72,
      "end": 2637.92,
      "text": "technique has different parameters to"
    },
    {
      "start": 2634.32,
      "end": 2641.2,
      "text": "tune. So I also see that uh there is an"
    },
    {
      "start": 2637.92,
      "end": 2644.4,
      "text": "uh evolving uh part of the all of these"
    },
    {
      "start": 2641.2,
      "end": 2647.36,
      "text": "um libraries but I can suggest open"
    },
    {
      "start": 2644.4,
      "end": 2649.92,
      "text": "agents SDK as a starting point uh to"
    },
    {
      "start": 2647.36,
      "end": 2652.56,
      "text": "basically start implementing specific uh"
    },
    {
      "start": 2649.92,
      "end": 2656.28,
      "text": "context engineering techniques uh and"
    },
    {
      "start": 2652.56,
      "end": 2656.28,
      "text": "and go from there."
    },
    {
      "start": 2656.8,
      "end": 2660.96,
      "text": "Nice."
    },
    {
      "start": 2658.48,
      "end": 2663.68,
      "text": "Next one. So how do you evaluate or"
    },
    {
      "start": 2660.96,
      "end": 2666.64,
      "text": "measure uh the memory feature is"
    },
    {
      "start": 2663.68,
      "end": 2668.08,
      "text": "evolving uh the memory is improving"
    },
    {
      "start": 2666.64,
      "end": 2672.08,
      "text": "performance. So this is a really nice"
    },
    {
      "start": 2668.08,
      "end": 2673.6,
      "text": "question. Um yeah after this the session"
    },
    {
      "start": 2672.08,
      "end": 2676.56,
      "text": "you might think about hey you know I"
    },
    {
      "start": 2673.6,
      "end": 2678.64,
      "text": "implemented a specific memory approach"
    },
    {
      "start": 2676.56,
      "end": 2682.16,
      "text": "but I don't know if it's if it's good or"
    },
    {
      "start": 2678.64,
      "end": 2685.92,
      "text": "or not how it's performing well. So we"
    },
    {
      "start": 2682.16,
      "end": 2688.24,
      "text": "can maybe split this into couple um uh"
    },
    {
      "start": 2685.92,
      "end": 2691.12,
      "text": "portions. So first one is basically just"
    },
    {
      "start": 2688.24,
      "end": 2693.76,
      "text": "running your your regular evals with"
    },
    {
      "start": 2691.12,
      "end": 2695.28,
      "text": "memory and and without memory. So I"
    },
    {
      "start": 2693.76,
      "end": 2697.28,
      "text": "think this is a really nice way to to"
    },
    {
      "start": 2695.28,
      "end": 2700.24,
      "text": "start thinking about if if memory"
    },
    {
      "start": 2697.28,
      "end": 2702.08,
      "text": "feature works or not. So if you have"
    },
    {
      "start": 2700.24,
      "end": 2703.6,
      "text": "some specific eval metrics like"
    },
    {
      "start": 2702.08,
      "end": 2706.24,
      "text": "completeness"
    },
    {
      "start": 2703.6,
      "end": 2709.44,
      "text": "uh like upwards downloads or that type"
    },
    {
      "start": 2706.24,
      "end": 2711.52,
      "text": "of uh numeric metrics you can see if"
    },
    {
      "start": 2709.44,
      "end": 2714.64,
      "text": "there's an increase or decrease or if"
    },
    {
      "start": 2711.52,
      "end": 2718.0,
      "text": "there's any statistically significant uh"
    },
    {
      "start": 2714.64,
      "end": 2720.8,
      "text": "uplift coming from the memory uh and"
    },
    {
      "start": 2718.0,
      "end": 2724.72,
      "text": "then maybe your evals might not be"
    },
    {
      "start": 2720.8,
      "end": 2727.52,
      "text": "capturing well that type of um memory"
    },
    {
      "start": 2724.72,
      "end": 2729.44,
      "text": "based boost or improvement then I I"
    },
    {
      "start": 2727.52,
      "end": 2731.28,
      "text": "suggest you to think about more memory"
    },
    {
      "start": 2729.44,
      "end": 2734.48,
      "text": "based eval. So what I mean by memory"
    },
    {
      "start": 2731.28,
      "end": 2738.0,
      "text": "based eval is basically uh evaluating"
    },
    {
      "start": 2734.48,
      "end": 2740.64,
      "text": "the model on long running tasks and long"
    },
    {
      "start": 2738.0,
      "end": 2744.0,
      "text": "context. So if you are not hitting any"
    },
    {
      "start": 2740.64,
      "end": 2746.4,
      "text": "um context thresholds maybe uh your"
    },
    {
      "start": 2744.0,
      "end": 2750.0,
      "text": "agent uh doesn't need any of these"
    },
    {
      "start": 2746.4,
      "end": 2751.76,
      "text": "memory um improvements at all. So again"
    },
    {
      "start": 2750.0,
      "end": 2754.24,
      "text": "you can start with your core core evals"
    },
    {
      "start": 2751.76,
      "end": 2756.08,
      "text": "if you have already and then secondly"
    },
    {
      "start": 2754.24,
      "end": 2758.72,
      "text": "you can start creating your own memory"
    },
    {
      "start": 2756.08,
      "end": 2761.6,
      "text": "based evals. So you can even evaluate"
    },
    {
      "start": 2758.72,
      "end": 2763.84,
      "text": "the the quality of the summary, you can"
    },
    {
      "start": 2761.6,
      "end": 2766.08,
      "text": "evaluate the injection time, you can"
    },
    {
      "start": 2763.84,
      "end": 2768.88,
      "text": "evaluate the injection prompt. So there"
    },
    {
      "start": 2766.08,
      "end": 2770.72,
      "text": "are different ways to to evaluate it. Uh"
    },
    {
      "start": 2768.88,
      "end": 2773.12,
      "text": "but of course in most EVAs you also"
    },
    {
      "start": 2770.72,
      "end": 2777.12,
      "text": "might need to prepare a golden data set"
    },
    {
      "start": 2773.12,
      "end": 2779.92,
      "text": "first and think about maybe like couple"
    },
    {
      "start": 2777.12,
      "end": 2783.12,
      "text": "50 examples like golden examples of a of"
    },
    {
      "start": 2779.92,
      "end": 2786.0,
      "text": "a good summary or you can try different"
    },
    {
      "start": 2783.12,
      "end": 2787.84,
      "text": "horistics that I mentioned before to"
    },
    {
      "start": 2786.0,
      "end": 2791.44,
      "text": "basically find the right balance of"
    },
    {
      "start": 2787.84,
      "end": 2794.32,
      "text": "trimming uh and compacting. So I think"
    },
    {
      "start": 2791.44,
      "end": 2796.16,
      "text": "we can just group this into three"
    },
    {
      "start": 2794.32,
      "end": 2798.24,
      "text": "different buckets. First one is running"
    },
    {
      "start": 2796.16,
      "end": 2800.4,
      "text": "your own evals to see see if there's an"
    },
    {
      "start": 2798.24,
      "end": 2803.04,
      "text": "uplift. Second one is building memory"
    },
    {
      "start": 2800.4,
      "end": 2805.2,
      "text": "specific evals. And the third one is"
    },
    {
      "start": 2803.04,
      "end": 2807.36,
      "text": "basically finding the right heristics uh"
    },
    {
      "start": 2805.2,
      "end": 2811.24,
      "text": "and parameters to apply in the in the"
    },
    {
      "start": 2807.36,
      "end": 2811.24,
      "text": "context engineering techniques."
    },
    {
      "start": 2812.08,
      "end": 2817.52,
      "text": "Next one. So should we use hierarchical"
    },
    {
      "start": 2814.16,
      "end": 2820.08,
      "text": "context like entire project context for"
    },
    {
      "start": 2817.52,
      "end": 2824.72,
      "text": "immediate task and context for immediate"
    },
    {
      "start": 2820.08,
      "end": 2826.32,
      "text": "file edit in questions? Um so yes the qu"
    },
    {
      "start": 2824.72,
      "end": 2829.52,
      "text": "the answer is yes but it's mostly"
    },
    {
      "start": 2826.32,
      "end": 2832.48,
      "text": "dependent on the use case. So we also"
    },
    {
      "start": 2829.52,
      "end": 2834.72,
      "text": "have a a concept called memory scope. So"
    },
    {
      "start": 2832.48,
      "end": 2837.6,
      "text": "you can think about this memory scope as"
    },
    {
      "start": 2834.72,
      "end": 2840.08,
      "text": "as a global scope that means if you have"
    },
    {
      "start": 2837.6,
      "end": 2841.52,
      "text": "a customer or user of your agent"
    },
    {
      "start": 2840.08,
      "end": 2843.12,
      "text": "probably there are some information that"
    },
    {
      "start": 2841.52,
      "end": 2845.68,
      "text": "you should always remember about that"
    },
    {
      "start": 2843.12,
      "end": 2848.56,
      "text": "specific user. Maybe this user likes"
    },
    {
      "start": 2845.68,
      "end": 2851.12,
      "text": "more friendly tones. Maybe this this"
    },
    {
      "start": 2848.56,
      "end": 2854.0,
      "text": "user lives in the US. So these are some"
    },
    {
      "start": 2851.12,
      "end": 2857.92,
      "text": "examples for global memory. Um but you"
    },
    {
      "start": 2854.0,
      "end": 2861.2,
      "text": "can also have um uh a scope based on the"
    },
    {
      "start": 2857.92,
      "end": 2864.8,
      "text": "specific session. So let's say I want to"
    },
    {
      "start": 2861.2,
      "end": 2866.56,
      "text": "uh book a travel uh and then this time I"
    },
    {
      "start": 2864.8,
      "end": 2869.2,
      "text": "prefer window seats because I want to"
    },
    {
      "start": 2866.56,
      "end": 2871.2,
      "text": "sleep. Uh so this also a nice example"
    },
    {
      "start": 2869.2,
      "end": 2874.0,
      "text": "about the the session scope and session"
    },
    {
      "start": 2871.2,
      "end": 2876.48,
      "text": "memories. So I think this is a good"
    },
    {
      "start": 2874.0,
      "end": 2879.12,
      "text": "practice to maybe separate these into"
    },
    {
      "start": 2876.48,
      "end": 2881.28,
      "text": "two two buckets and you can keep track"
    },
    {
      "start": 2879.12,
      "end": 2884.0,
      "text": "of uh session memories with session"
    },
    {
      "start": 2881.28,
      "end": 2886.8,
      "text": "scope and over time you can graduate"
    },
    {
      "start": 2884.0,
      "end": 2888.56,
      "text": "session memories into global memories"
    },
    {
      "start": 2886.8,
      "end": 2891.2,
      "text": "and you can keep track of like what is"
    },
    {
      "start": 2888.56,
      "end": 2893.92,
      "text": "really important uh about uh the"
    },
    {
      "start": 2891.2,
      "end": 2896.88,
      "text": "specific user. So in travel concier"
    },
    {
      "start": 2893.92,
      "end": 2900.0,
      "text": "example if user is always saying hey"
    },
    {
      "start": 2896.88,
      "end": 2902.16,
      "text": "this time I want window seat uh like"
    },
    {
      "start": 2900.0,
      "end": 2904.4,
      "text": "maybe multiple times and you can finally"
    },
    {
      "start": 2902.16,
      "end": 2908.08,
      "text": "graduate that memory into global"
    },
    {
      "start": 2904.4,
      "end": 2910.8,
      "text": "memories and keep track uh keep it in in"
    },
    {
      "start": 2908.08,
      "end": 2915.16,
      "text": "agent's mind basically and remember that"
    },
    {
      "start": 2910.8,
      "end": 2915.16,
      "text": "for the next uh next bookings."
    },
    {
      "start": 2916.88,
      "end": 2922.32,
      "text": "Nice. Okay. So what strategies do you do"
    },
    {
      "start": 2919.92,
      "end": 2923.92,
      "text": "you use to keep memory flash or prune so"
    },
    {
      "start": 2922.32,
      "end": 2927.36,
      "text": "the agent doesn't become overloaded with"
    },
    {
      "start": 2923.92,
      "end": 2930.4,
      "text": "stale or yeah this is a really um this"
    },
    {
      "start": 2927.36,
      "end": 2933.36,
      "text": "is another good question uh and in the"
    },
    {
      "start": 2930.4,
      "end": 2937.28,
      "text": "real world you see that memories are are"
    },
    {
      "start": 2933.36,
      "end": 2938.88,
      "text": "evolving really fast so after some time"
    },
    {
      "start": 2937.28,
      "end": 2942.0,
      "text": "you'll see that there are some memories"
    },
    {
      "start": 2938.88,
      "end": 2945.04,
      "text": "that you need to prune and the agent"
    },
    {
      "start": 2942.0,
      "end": 2946.4,
      "text": "needs to forget. So in that specific"
    },
    {
      "start": 2945.04,
      "end": 2948.88,
      "text": "case there are a couple techniques to"
    },
    {
      "start": 2946.4,
      "end": 2952.08,
      "text": "apply. So first of them first of it is"
    },
    {
      "start": 2948.88,
      "end": 2955.6,
      "text": "basically keeping a temporal tax. Okay,"
    },
    {
      "start": 2952.08,
      "end": 2958.4,
      "text": "I I learned this memory uh from the user"
    },
    {
      "start": 2955.6,
      "end": 2961.84,
      "text": "but I learned it maybe like two months"
    },
    {
      "start": 2958.4,
      "end": 2965.12,
      "text": "ago. So if you can keep track of these"
    },
    {
      "start": 2961.84,
      "end": 2967.36,
      "text": "um timestamps uh or temporal tags, the"
    },
    {
      "start": 2965.12,
      "end": 2971.36,
      "text": "model will understand what is old and"
    },
    {
      "start": 2967.36,
      "end": 2973.04,
      "text": "what is new. So if I say I like dogs, if"
    },
    {
      "start": 2971.36,
      "end": 2975.52,
      "text": "I said I like dogs like two months ago"
    },
    {
      "start": 2973.04,
      "end": 2976.48,
      "text": "and today I say I like cats. So you'll"
    },
    {
      "start": 2975.52,
      "end": 2978.32,
      "text": "see that the model is going to"
    },
    {
      "start": 2976.48,
      "end": 2981.12,
      "text": "understand my favorite animal now is"
    },
    {
      "start": 2978.32,
      "end": 2984.32,
      "text": "maybe cats and it will override the"
    },
    {
      "start": 2981.12,
      "end": 2986.32,
      "text": "memory um with the right instructions."
    },
    {
      "start": 2984.32,
      "end": 2988.16,
      "text": "So this also falls into a little bit to"
    },
    {
      "start": 2986.32,
      "end": 2991.2,
      "text": "memor consolidation."
    },
    {
      "start": 2988.16,
      "end": 2994.08,
      "text": "So how to prune uh stale memories, how"
    },
    {
      "start": 2991.2,
      "end": 2996.8,
      "text": "to basically update uh and override the"
    },
    {
      "start": 2994.08,
      "end": 2998.96,
      "text": "new ones into the existing ones. So"
    },
    {
      "start": 2996.8,
      "end": 3001.28,
      "text": "temporal text is one technique that you"
    },
    {
      "start": 2998.96,
      "end": 3004.56,
      "text": "can apply. Uh the other one is you can"
    },
    {
      "start": 3001.28,
      "end": 3008.88,
      "text": "use a way decay or um basically a window"
    },
    {
      "start": 3004.56,
      "end": 3012.56,
      "text": "function uh and you can basically uh"
    },
    {
      "start": 3008.88,
      "end": 3014.48,
      "text": "focus more on the recent memories uh and"
    },
    {
      "start": 3012.56,
      "end": 3017.04,
      "text": "you can basically downgrade the the"
    },
    {
      "start": 3014.48,
      "end": 3020.16,
      "text": "oldest ones. So it really depends on the"
    },
    {
      "start": 3017.04,
      "end": 3022.64,
      "text": "nature of your use case. So if you think"
    },
    {
      "start": 3020.16,
      "end": 3024.64,
      "text": "that what I said a year ago is not"
    },
    {
      "start": 3022.64,
      "end": 3026.48,
      "text": "important for your agent, uh you can"
    },
    {
      "start": 3024.64,
      "end": 3029.2,
      "text": "definitely prune these old ones and"
    },
    {
      "start": 3026.48,
      "end": 3031.52,
      "text": "implement a weighted average probably"
    },
    {
      "start": 3029.2,
      "end": 3034.16,
      "text": "for all your memories. But if you think"
    },
    {
      "start": 3031.52,
      "end": 3036.56,
      "text": "that all of this memory is is equally"
    },
    {
      "start": 3034.16,
      "end": 3039.36,
      "text": "important for your agent, then you can"
    },
    {
      "start": 3036.56,
      "end": 3041.44,
      "text": "consider maybe like memory consolidation"
    },
    {
      "start": 3039.36,
      "end": 3044.4,
      "text": "and memory override with temporal text."
    },
    {
      "start": 3041.44,
      "end": 3047.84,
      "text": "So we can talk about two different uh"
    },
    {
      "start": 3044.4,
      "end": 3052.04,
      "text": "techniques um to manage the overloaded"
    },
    {
      "start": 3047.84,
      "end": 3052.04,
      "text": "and stale uh memories."
    },
    {
      "start": 3054.64,
      "end": 3059.84,
      "text": "Nice. Okay. So how do you manage scaling"
    },
    {
      "start": 3057.68,
      "end": 3062.08,
      "text": "agent memory systems when you have many"
    },
    {
      "start": 3059.84,
      "end": 3064.8,
      "text": "users with individual"
    },
    {
      "start": 3062.08,
      "end": 3066.32,
      "text": "and shared memory pools?"
    },
    {
      "start": 3064.8,
      "end": 3070.08,
      "text": "Yeah, this also another good good"
    },
    {
      "start": 3066.32,
      "end": 3072.48,
      "text": "example from real world. Um so once you"
    },
    {
      "start": 3070.08,
      "end": 3074.48,
      "text": "see the memories are are uh evolving"
    },
    {
      "start": 3072.48,
      "end": 3077.84,
      "text": "over time and you'll see that you're"
    },
    {
      "start": 3074.48,
      "end": 3080.56,
      "text": "collecting tons of memories from um from"
    },
    {
      "start": 3077.84,
      "end": 3082.96,
      "text": "your users. Um so there are different"
    },
    {
      "start": 3080.56,
      "end": 3085.36,
      "text": "ways to scale it. I think the first path"
    },
    {
      "start": 3082.96,
      "end": 3089.12,
      "text": "or first first decision criteria starts"
    },
    {
      "start": 3085.36,
      "end": 3091.2,
      "text": "with if you are basically performing uh"
    },
    {
      "start": 3089.12,
      "end": 3094.24,
      "text": "a retrieval or search base long"
    },
    {
      "start": 3091.2,
      "end": 3097.6,
      "text": "long-term memory approach or you're just"
    },
    {
      "start": 3094.24,
      "end": 3099.92,
      "text": "using um basically summarizing the the"
    },
    {
      "start": 3097.6,
      "end": 3101.68,
      "text": "context. So if it's the the second one"
    },
    {
      "start": 3099.92,
      "end": 3104.16,
      "text": "that means you're just storing all of"
    },
    {
      "start": 3101.68,
      "end": 3106.16,
      "text": "this information and persisted into into"
    },
    {
      "start": 3104.16,
      "end": 3108.56,
      "text": "a disk. So you can think about some"
    },
    {
      "start": 3106.16,
      "end": 3111.52,
      "text": "scaling methods about like data"
    },
    {
      "start": 3108.56,
      "end": 3114.8,
      "text": "management how to manage like a large"
    },
    {
      "start": 3111.52,
      "end": 3117.76,
      "text": "amount of memory nodes uh as a text in a"
    },
    {
      "start": 3114.8,
      "end": 3121.68,
      "text": "text format"
    },
    {
      "start": 3117.76,
      "end": 3123.36,
      "text": "or you can basically think about um"
    },
    {
      "start": 3121.68,
      "end": 3124.88,
      "text": "scaling the first approach which is"
    },
    {
      "start": 3123.36,
      "end": 3128.16,
      "text": "basically you have to think about like"
    },
    {
      "start": 3124.88,
      "end": 3130.64,
      "text": "how to scale a search uh and retrieval"
    },
    {
      "start": 3128.16,
      "end": 3133.6,
      "text": "system. you might be storing all of this"
    },
    {
      "start": 3130.64,
      "end": 3135.76,
      "text": "information um into into a vector"
    },
    {
      "start": 3133.6,
      "end": 3137.84,
      "text": "database and then in this vector"
    },
    {
      "start": 3135.76,
      "end": 3140.08,
      "text": "database you can try to scaling uh the"
    },
    {
      "start": 3137.84,
      "end": 3143.76,
      "text": "storage you can scale all these all"
    },
    {
      "start": 3140.08,
      "end": 3145.36,
      "text": "these vectors filtering ranking system"
    },
    {
      "start": 3143.76,
      "end": 3147.2,
      "text": "and all of that so I think the first"
    },
    {
      "start": 3145.36,
      "end": 3149.84,
      "text": "bucket is mostly about this long-term"
    },
    {
      "start": 3147.2,
      "end": 3152.4,
      "text": "memory so we talked about like memory as"
    },
    {
      "start": 3149.84,
      "end": 3154.4,
      "text": "a tool so if you can think about"
    },
    {
      "start": 3152.4,
      "end": 3156.72,
      "text": "extracting memories with a tool and"
    },
    {
      "start": 3154.4,
      "end": 3158.32,
      "text": "retrieving back during the live turns"
    },
    {
      "start": 3156.72,
      "end": 3160.16,
      "text": "probably this is the situation where"
    },
    {
      "start": 3158.32,
      "end": 3163.76,
      "text": "you're going to uh hit this question"
    },
    {
      "start": 3160.16,
      "end": 3166.4,
      "text": "about scaling uh for many users. Uh in"
    },
    {
      "start": 3163.76,
      "end": 3169.28,
      "text": "this case you can think about u scaling"
    },
    {
      "start": 3166.4,
      "end": 3172.32,
      "text": "techniques for vector databases. Uh you"
    },
    {
      "start": 3169.28,
      "end": 3174.08,
      "text": "can use shorting you can optimize your"
    },
    {
      "start": 3172.32,
      "end": 3176.56,
      "text": "embeddings model probably if you're"
    },
    {
      "start": 3174.08,
      "end": 3178.96,
      "text": "using like customized embedding model."
    },
    {
      "start": 3176.56,
      "end": 3181.52,
      "text": "Um and you can basically optimize"
    },
    {
      "start": 3178.96,
      "end": 3185.12,
      "text": "retrieval process similar to to a rag"
    },
    {
      "start": 3181.52,
      "end": 3188.0,
      "text": "approach. Uh again the first one uh is"
    },
    {
      "start": 3185.12,
      "end": 3190.64,
      "text": "mostly about scaling a retrieval system."
    },
    {
      "start": 3188.0,
      "end": 3192.24,
      "text": "Uh the second one is mostly about"
    },
    {
      "start": 3190.64,
      "end": 3195.36,
      "text": "basically like data storage, how to"
    },
    {
      "start": 3192.24,
      "end": 3197.84,
      "text": "store specific data, how to manage uh"
    },
    {
      "start": 3195.36,
      "end": 3201.04,
      "text": "like tons of information and sentences."
    },
    {
      "start": 3197.84,
      "end": 3204.32,
      "text": "I think to wrap up uh we can basically"
    },
    {
      "start": 3201.04,
      "end": 3206.08,
      "text": "put it into two buckets. One of them is"
    },
    {
      "start": 3204.32,
      "end": 3209.36,
      "text": "uh scaling"
    },
    {
      "start": 3206.08,
      "end": 3213.04,
      "text": "um and optimizing a retrieval system. Uh"
    },
    {
      "start": 3209.36,
      "end": 3215.68,
      "text": "the second one is is also u"
    },
    {
      "start": 3213.04,
      "end": 3219.44,
      "text": "making more efficient for storing and"
    },
    {
      "start": 3215.68,
      "end": 3221.44,
      "text": "persistent uh in in the disk."
    },
    {
      "start": 3219.44,
      "end": 3225.6,
      "text": "So this is also a common question that I"
    },
    {
      "start": 3221.44,
      "end": 3228.0,
      "text": "hear from from my customers. Um I think"
    },
    {
      "start": 3225.6,
      "end": 3231.44,
      "text": "you can maybe follow like a like pilot"
    },
    {
      "start": 3228.0,
      "end": 3234.48,
      "text": "approach and you can turn on this new uh"
    },
    {
      "start": 3231.44,
      "end": 3237.12,
      "text": "memory techniques for for for a subgroup"
    },
    {
      "start": 3234.48,
      "end": 3239.6,
      "text": "of your users and you can think about"
    },
    {
      "start": 3237.12,
      "end": 3241.84,
      "text": "okay how it's evolving over time. Maybe"
    },
    {
      "start": 3239.6,
      "end": 3243.76,
      "text": "you'll see that most of the memories"
    },
    {
      "start": 3241.84,
      "end": 3245.76,
      "text": "that your users are saying are pretty"
    },
    {
      "start": 3243.76,
      "end": 3248.32,
      "text": "limited. So think about this travel"
    },
    {
      "start": 3245.76,
      "end": 3250.8,
      "text": "concier agent. So probably I'll just"
    },
    {
      "start": 3248.32,
      "end": 3253.76,
      "text": "sharing my my memories about my seat"
    },
    {
      "start": 3250.8,
      "end": 3256.24,
      "text": "preference. Maybe if you want to book a"
    },
    {
      "start": 3253.76,
      "end": 3259.44,
      "text": "hotel, I like maybe higher floors. Maybe"
    },
    {
      "start": 3256.24,
      "end": 3263.04,
      "text": "I like the specific menu or breakfast."
    },
    {
      "start": 3259.44,
      "end": 3265.6,
      "text": "Uh so I think this is more limited type"
    },
    {
      "start": 3263.04,
      "end": 3268.0,
      "text": "of groups uh type of memory memory"
    },
    {
      "start": 3265.6,
      "end": 3270.56,
      "text": "possibilities I can say and that type of"
    },
    {
      "start": 3268.0,
      "end": 3273.28,
      "text": "agent. But you are if you're building a"
    },
    {
      "start": 3270.56,
      "end": 3274.96,
      "text": "life coach or life coach agent. So there"
    },
    {
      "start": 3273.28,
      "end": 3279.04,
      "text": "are tons of memories that you need to"
    },
    {
      "start": 3274.96,
      "end": 3281.52,
      "text": "remember uh about me my life. uh and"
    },
    {
      "start": 3279.04,
      "end": 3283.6,
      "text": "you'll see that these type of memories"
    },
    {
      "start": 3281.52,
      "end": 3287.04,
      "text": "and memory pools are evolving really"
    },
    {
      "start": 3283.6,
      "end": 3289.44,
      "text": "fast. So yeah the third point is that"
    },
    {
      "start": 3287.04,
      "end": 3292.08,
      "text": "try to understand the the evolution of"
    },
    {
      "start": 3289.44,
      "end": 3294.56,
      "text": "memory and possibilities of memory in"
    },
    {
      "start": 3292.08,
      "end": 3297.36,
      "text": "your AI agent. So we have two examples"
    },
    {
      "start": 3294.56,
      "end": 3300.16,
      "text": "here travel concierge memories and then"
    },
    {
      "start": 3297.36,
      "end": 3301.84,
      "text": "life coach memories. So yeah as you see"
    },
    {
      "start": 3300.16,
      "end": 3304.96,
      "text": "in the second one you'll be collecting"
    },
    {
      "start": 3301.84,
      "end": 3308.0,
      "text": "tons of information that is valuable for"
    },
    {
      "start": 3304.96,
      "end": 3311.12,
      "text": "uh yeah for my life. Um and then my"
    },
    {
      "start": 3308.0,
      "end": 3313.84,
      "text": "dreams, my goals, uh what I was thinking"
    },
    {
      "start": 3311.12,
      "end": 3316.24,
      "text": "a month ago or a year ago. So the second"
    },
    {
      "start": 3313.84,
      "end": 3319.44,
      "text": "one is is mostly like super advanced and"
    },
    {
      "start": 3316.24,
      "end": 3325.68,
      "text": "complex and sophisticated memorable that"
    },
    {
      "start": 3319.44,
      "end": 3328.64,
      "text": "requires uh lots of scaling uh for sure."
    },
    {
      "start": 3325.68,
      "end": 3331.04,
      "text": "Okay. Um so yeah, that was the end of"
    },
    {
      "start": 3328.64,
      "end": 3331.68,
      "text": "the the question the the Q&A session"
    },
    {
      "start": 3331.04,
      "end": 3334.68,
      "text": "probably."
    },
    {
      "start": 3331.68,
      "end": 3334.68,
      "text": ">> Yeah."
    },
    {
      "start": 3335.04,
      "end": 3339.68,
      "text": ">> Okay. Um yeah, and then we can just"
    },
    {
      "start": 3336.56,
      "end": 3341.44,
      "text": "switch to resources. So um all right,"
    },
    {
      "start": 3339.68,
      "end": 3344.56,
      "text": "this has been awesome. To wrap things"
    },
    {
      "start": 3341.44,
      "end": 3346.72,
      "text": "up, um we're we've linked a few great"
    },
    {
      "start": 3344.56,
      "end": 3348.16,
      "text": "resources here, including the context"
    },
    {
      "start": 3346.72,
      "end": 3349.28,
      "text": "engineering cookbook, which was"
    },
    {
      "start": 3348.16,
      "end": 3351.92,
      "text": "referenced, and the context"
    },
    {
      "start": 3349.28,
      "end": 3354.4,
      "text": "summarization cookbook and our agents"
    },
    {
      "start": 3351.92,
      "end": 3356.64,
      "text": "Python SDK. I know we've gotten a lot of"
    },
    {
      "start": 3354.4,
      "end": 3358.48,
      "text": "questions on is this available in"
    },
    {
      "start": 3356.64,
      "end": 3360.4,
      "text": "GitHub. So you can explore all of these"
    },
    {
      "start": 3358.48,
      "end": 3363.92,
      "text": "links on the right and the full build"
    },
    {
      "start": 3360.4,
      "end": 3367.28,
      "text": "hour repo is available on GitHub."
    },
    {
      "start": 3363.92,
      "end": 3369.2,
      "text": "Um, so good news. We're likely going to"
    },
    {
      "start": 3367.28,
      "end": 3371.12,
      "text": "squeeze one or two more of these in"
    },
    {
      "start": 3369.2,
      "end": 3373.36,
      "text": "before the end of the year. So keep an"
    },
    {
      "start": 3371.12,
      "end": 3375.36,
      "text": "eye out on our build hours page linked"
    },
    {
      "start": 3373.36,
      "end": 3378.24,
      "text": "here."
    },
    {
      "start": 3375.36,
      "end": 3380.24,
      "text": "And um, a big thank you all so much for"
    },
    {
      "start": 3378.24,
      "end": 3382.4,
      "text": "tuning in and a big thanks to Emmery"
    },
    {
      "start": 3380.24,
      "end": 3383.68,
      "text": "who's did an amazing job with this"
    },
    {
      "start": 3382.4,
      "end": 3386.0,
      "text": "session."
    },
    {
      "start": 3383.68,
      "end": 3388.4,
      "text": ">> Yeah, thanks everyone. Uh, we hope you"
    },
    {
      "start": 3386.0,
      "end": 3390.72,
      "text": "enjoyed uh, this build hour on an agent"
    },
    {
      "start": 3388.4,
      "end": 3393.28,
      "text": "member patterns. I know we covered like"
    },
    {
      "start": 3390.72,
      "end": 3395.6,
      "text": "lots of different techniques uh lots of"
    },
    {
      "start": 3393.28,
      "end": 3397.92,
      "text": "different information about memory, how"
    },
    {
      "start": 3395.6,
      "end": 3400.24,
      "text": "to think about memory, how to design"
    },
    {
      "start": 3397.92,
      "end": 3403.84,
      "text": "memory. So, so overall as you see there"
    },
    {
      "start": 3400.24,
      "end": 3406.08,
      "text": "are too many options but the core uh"
    },
    {
      "start": 3403.84,
      "end": 3408.96,
      "text": "idea is basically better understanding"
    },
    {
      "start": 3406.08,
      "end": 3410.32,
      "text": "what your agent should remember and how"
    },
    {
      "start": 3408.96,
      "end": 3412.4,
      "text": "it should remember and how it should"
    },
    {
      "start": 3410.32,
      "end": 3414.48,
      "text": "forget. So you can think about these"
    },
    {
      "start": 3412.4,
      "end": 3418.88,
      "text": "three things when you're designing your"
    },
    {
      "start": 3414.48,
      "end": 3420.88,
      "text": "own agent u memory. Uh and this is still"
    },
    {
      "start": 3418.88,
      "end": 3424.72,
      "text": "an evolving field. So you you might see"
    },
    {
      "start": 3420.88,
      "end": 3427.44,
      "text": "like some um like new features coming uh"
    },
    {
      "start": 3424.72,
      "end": 3428.96,
      "text": "about memory overall. Uh but yeah, I"
    },
    {
      "start": 3427.44,
      "end": 3432.56,
      "text": "just wanted to show you like different"
    },
    {
      "start": 3428.96,
      "end": 3434.8,
      "text": "design tradeoffs uh and and guide you"
    },
    {
      "start": 3432.56,
      "end": 3436.64,
      "text": "with the with the best option. So"
    },
    {
      "start": 3434.8,
      "end": 3439.12,
      "text": "finding the right balance between these"
    },
    {
      "start": 3436.64,
      "end": 3442.56,
      "text": "techniques are uh usually like related"
    },
    {
      "start": 3439.12,
      "end": 3444.72,
      "text": "to your specific uh use case. And then"
    },
    {
      "start": 3442.56,
      "end": 3446.96,
      "text": "you can keep track of all of all the"
    },
    {
      "start": 3444.72,
      "end": 3448.32,
      "text": "news and cookbooks uh in the resources"
    },
    {
      "start": 3446.96,
      "end": 3451.92,
      "text": "section. So, I'll be also upload"
    },
    {
      "start": 3448.32,
      "end": 3454.08,
      "text": "uploading this um demo page uh so demo"
    },
    {
      "start": 3451.92,
      "end": 3456.8,
      "text": "application to to our build hours"
    },
    {
      "start": 3454.08,
      "end": 3458.4,
      "text": "GitHub. Uh and then yeah, thank you for"
    },
    {
      "start": 3456.8,
      "end": 3460.56,
      "text": "your time and thank you for for"
    },
    {
      "start": 3458.4,
      "end": 3462.32,
      "text": "listening uh all of this."
    },
    {
      "start": 3460.56,
      "end": 3465.44,
      "text": ">> Yeah, have a great rest of your day and"
    },
    {
      "start": 3462.32,
      "end": 3465.44,
      "text": "we'll see you next time."
    }
  ],
  "word_count": 8792,
  "fetched_at": "2025-12-21T02:19:24.839686Z"
}